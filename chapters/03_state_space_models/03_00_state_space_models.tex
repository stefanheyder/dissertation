\glsresetall
\newcommand{\acem}{\acrshort{cem}\xspace}
\newcommand{\ce}{{\ensuremath{\text{CE}}}}
\newcommand{\pce}{{\ensuremath{\psi_{\text{CE}}}}}
\newcommand{\hpce}{{\ensuremath{\hat\psi_{\text{CE}}}}}

\newcommand{\aeis}{\acrshort{eis}\xspace}
\newcommand{\eis}{{\ensuremath{\text{EIS}}}}
\newcommand{\peis}{{\ensuremath{\psi_{\text{EIS}}}}}
\newcommand{\hpeis}{{\ensuremath{\hat\psi_{\text{EIS}}}}}

\newcommand{\Pp}{{\ensuremath{\mathbb P^{X| Y=y}}}}
\newcommand{\Pps}{{\ensuremath{\mathbb P^{S| Y=y}}}}

\newcommand{\la}{{\ensuremath{\text{LA}}}}

\newcommand{\Dto}{\stackrel{\mathcal D}{\to}}
\newcommand{\id}{\operatorname{id}}


\newcommand{\nbinom}{\operatorname{NegBinom}}
\newcommand{\bdiag}{\operatorname{block-diag}}

\chapter{Importance Sampling in State Space Models}
\label{cha:state_space_models}
\newpage
\begin{tcolorbox}[title={Contributions}]
    The main contribution of this chapter consists of a rigorous comparison of two importance sampling frameworks: the \Acrfull{cem} and \Acrfull{eis}. Both methods determine optimal importance sampling proposals, but have, until now, been studied in separate communities: the \acem is popular in rare-event estimation and engineering disciplines, while \aeis is popular in the financial time series community. 

    The contributions of the individual sections are as follows:

    %\paragraph{\nameref{sec:modelling_epidemiological_dessiderata_with_state_space_models}} 

    \paragraph{\nameref{sec:linear_gaussian_state_space_models}} This section is loosely based on \citep{Durbin2012Time}.
    \paragraph{\nameref{sec:logconcave_gaussian_state_space_models}} This section is loosely based on \citep{Durbin2012Time,Brown1986Fundamentals}.
    \paragraph{\nameref{sec:importance_sampling}} While the general treatment of importance sampling is based on \citep{Chopin2020Introduction,Durbin2012Time}, we contribute the following:
    \begin{itemize}
        \item We prove \Cref{lem:bounded-log-variance} and \Cref{cor:dkl_bounded}.
        \item Discussion surrounding \Cref{thm:chatterje2018Thm1}, especially \Cref{ex:ess_failure}.
        \item The analysis of asymptotics of importance sampling methods, i.e. \Cref{prop:is-consistency,prop:is-clt}.
        \item The consistency and CLT results for the \acrshort{cem} (\Cref{thm:cem-consistent,thm:cem-clt}) and \acrshort{eis} (\Cref{thm:eis-consistent,thm:eis-clt}).
        \item The discussion of assumptions required in the CLTs for practical applications.
    \end{itemize}

    \paragraph{\nameref{sec:interim-discussion}}
    The whole section is newly contributed.

    \paragraph{\nameref{sec:gaussian_importance_sampling_for_state_space_models}}
    \begin{itemize}
        \item The discussion surrounding the difficulties the \acrshort{cem} faces when applied to the \acrshort{glssm} proposal.
        \item The derivation of the \acrshort{cem} for Markov-proposals (\Cref{prop:cem-for-markov-proposal}), resulting in \Cref{alg:cem-markov-proposal} and the optimized \Cref{alg:cem-markov-proposal-fast}.
    \end{itemize}

    \paragraph{\nameref{sec:maximum_likelihood_estimation}}
    This section is for the largest part based on literature, however the following points are new:
    \begin{itemize}
        \item The discussion of calculating the gradient, \Cref{eq:gradient_infeasible}, for the \acrshort{la} / \acrshort{eis}.
        \item We make the antithetic variable construction of \citep{Durbin1997Monte} rigorous. 
        \item \Cref{subsec:inference} is a rigorous reformulation of \citep[Section 11.5]{Durbin2012Time}.
    \end{itemize}

    \paragraph{\nameref{sec:simulation_studies}} 
    This whole section is a new contribution, extensively comparing the \acrshort{cem} with \acrshort{eis}.
\end{tcolorbox}
\newpage

In the last chapter, we have detailed the need for models capable of modeling complex epidemiological phenomena. Crucially, we must account for the time-series and discrete nature of the data at hand. 
\Glspl{ssm} form a versatile class of statistical models that allow modeling of non-stationary time series data while providing a straightforward, mechanistic interpretation of the time series' dynamics.
The main idea of these models is to introduce unobserved \textbf{latent states} whose joint distribution is governed by a Markov process, and to model the observed time series conditional on these states.
By exploiting this structure, inference in \glspl{ssm} becomes computationally efficient, as the complexity of algorithms is linear in the number $n$ of time points considered. 
In this chapter, we provide a mathematical introduction to the theory of \acrshortpl{ssm} and the main tool we will use for inference: importance sampling. 
%Additionally, we will highlight how to use \acrshortpl{ssm} to model the desiderata identified in \Cref{sec:dessiderata}. 
The foundations of \acrshortpl{ssm} presented in this chapter are, if not mentioned otherwise, based on \citep{Durbin2012Time,Chopin2020Introduction}.

Let us start from a very general definition of a \acrshort{ssm}.

\begin{definition}[State Space Model]
    \label{def:ssm}
    A \textbf{\acrlong{ssm}} is a discrete time stochastic process $(X_t, Y_t)_{t=0, \dots, n}$ taking values in the measurable space $\left(\mathcal X \times \mathcal Y, \mathcal B_{\mathcal X} \otimes \mathcal B_{\mathcal Y}\right)$ such that
    \begin{enumerate}
        \item The marginal distribution of the \textbf{states} $(X_0, \dots, X_{n})$ is a discrete time Markov process, i.e. for $t = 1, \dots, n$
              \begin{align}
                  \label{eq:markov_property}
                  \P \left( X_{t} \in B \middle| X_0, \dots, X_{t - 1} \right) = \P \left( X_{t} \in B \middle| X_{t - 1} \right) \text{ a.s.}
              \end{align}
              for all measurable $B \in \mathcal B_{\mathcal X}$.
        \item Conditional on the state $X_t$ and observation $Y_{t - 1}$, $Y_t$ is independent of $X_s$ and $Y_{s - 1}$, $s < t$, i.e.
              \begin{align*}
                  \P \left( Y_{t} \in B \middle| X_{0}, \dots, X_{t}, Y_{0}, \dots, Y_{t - 1} \right) & = \P \left( Y_{t} \in B | X_{t}, Y_{t - 1} \right)
              \end{align*}
              for all measurable $B \in \mathcal B _{\mathcal Y}$.
    \end{enumerate}
\end{definition}

For notational convenience, we will write $\gls{sym:Xs-to-t} = \left(X_s, \dots, X_{t}\right)$ for the vector that contains all states from $s$ to $t$, $s \leq t$, dropping the first index if we consider the whole set of observations up to time $t$, so $\gls{sym:X-to-t} = X_{0:t}$, and dropping the subscript if we consider all states at once, $X = X_{:n}$.
Similarly we set $Y_{s:t} = \left(Y_s, \dots, Y_{t}\right)$, $Y_{:t} = Y_{0:t}$ and $Y = Y_{:n}$.

The models that we consider in this thesis will usually assume that densities for the state transitions with respect to a common dominating measure $\mu_{\mathcal X}$ and similar for the observations with respect to some dominating measure $\mu_{\mathcal Y}$ exist. 

\begin{notation}[Densities, conditional densities]
    \label{not:densities}
    We will use the standard abuse of notation for densities that makes the type of density ``{}obvious''{} from the arguments used.
    This means that $\gls{sym:p}(x)$ is the density for all states $X$, evaluated at $x$, $p(x_t|x_{t - 1})$ the conditional density of $X_t|X_{t - 1}$, evaluated at $x_{t}$ and $x_{t - 1}$ and similarly for observations: $p(y|x)$ is the density of the conditional distribution of all observations $Y$ conditioned on all states $X$, evaluated at $y$ and $x$.

    Note that this notation also implicitly includes the time $t$ and allows for changes in, e.g., the state transition over time.

    When densities come from a parametric model parametrized by $\gls{sym:theta}\in \gls{sym:Theta} \subseteq \mathbf{R}^{l}$ and the dependence of the model on $\theta$ is of interest, e.g. because we try to estimate $\theta$, we indicate this by adding a subscript to the densities.
    If this dependence is not of interest, e.g. because $\theta$ is fixed, we omit $\theta$ for better readability.

    In this notation, the joint density of a parametric \gls{ssm} factorizes as
    \begin{align}
        \label{eq:joint_density}
        \begin{split}
        p_\theta(x,y) & = p_\theta(x_0, \dots, x_{n}, y_0, \dots, y_{n})                                                              \\
                      & = p_\theta (x_0)\prod_{t = 1}^{n} p_\theta(x_{t}|x_{t - 1}) \prod_{t = 0}^{n} p_\theta(y_t | x_t, y_{t - 1}),
        \end{split}
    \end{align}
    where $p_\theta(y_0|x_0, y_{-1}) = p_\theta(y_0| x_0)$.

    As inferences made in this thesis depend on the \gls{ssm} only through the likelihood we identify almost sure versions of $(X, Y)$ with themselves, i.e. all equations involving $X$ or $Y$ are understood almost surely.
\end{notation}

\begin{remark}[dependence on $Y_{t - 1}$, dimensions]
    \label{rem:dependence_Yt-1}
    Contrary to the standard definition of a \gls{ssm}, as found in, e.g., \citep[Chapter 2]{Chopin2020Introduction} or \citep[Chapter 9]{Durbin2012Time}, our \Cref{def:ssm} allows $Y_t$ to depend on $Y_{t - 1}$.
    As the models considered in \Cref{cha:analysis_of_selected_models} will make extensive use of \glspl{ssm} with this dependency structure we opt to use this non-standard definition here.
    This is of course not a limitation of the standard definition: given a \gls{ssm} of the form described in \Cref{def:ssm}, we can transform it to the standard form by choosing states $(X_t, Y_t) \in \mathcal X \times \mathcal Y$ and observations $Y_t \in \mathcal Y$ such that the \gls{ssm} becomes a stochastic process on $ \left( \mathcal X \times \mathcal Y\right) \times \mathcal Y$.

    Additionally, the goal of our inferences will always be functionals of the conditional distribution $X|Y$ for a single, fixed, set of observations $y$. Assuming all densities exist, the conditional density $p(x|y)$ is given, up to a constant not depending on $x$, by \Cref{eq:joint_density}:
    $$
    p(x|y) \propto p(x,y) =p (x_0)\prod_{t = 1}^{n} p(x_{t}|x_{t - 1}) \prod_{t = 0}^{n} p(y_t | x_t, y_{t - 1}).
    $$
    Thus, the dependence of $Y_{t}$ on $Y_{t - 1}$ only affects our inferences through $p(y_{t} | x_{t}, y_{t - 1})$, where, as $Y_{t - 1}$ is observed, the argument $y_{t - 1}$ is fixed. By a similar argument, we could allow $Y_{t}$ to depend on all previous observations $Y_{0}, \dots, Y_{t - 1}$ without changing any of our inferences. However, the models presented in \Cref{cha:analysis_of_selected_models} will not make use of this further generalization.
    Consequently, all results we present in this chapter for \acrshortpl{ssm} where $Y_{t}$ depends only on $X_{t}$ that concern only the conditional distribution $X|Y=y$ carry over to those given by \Cref{def:ssm}. We will reiterate this argument at appropriate points in this thesis.

    In most \acrshortpl{ssm} we consider in this thesis we use $\mathcal X = \R^m$ and $\mathcal Y = \R^p$ or $\mathcal Y = \Z^p$ so that $\mathcal X$ is $m$ dimensional and $\mathcal Y$ is $p$ dimensional and equip these spaces with the usual $\sigma$-Algebras. Unless noted otherwise, we use for $\mu_{\mathcal X}$ the $m$-dimensional Lebesgue measure and for $\mu_{\mathcal Y}$ either the $p$-dimensional Lebesgue measure ($\mathcal Y = \R^{p}$) or the $p$-dimensional counting measure ($\mathcal Y = \Z^{p}$).
    
\end{remark}

\begin{figure}
    \centering
    \input{tikz/manual/ssm_dependencies.tex}%
    \caption{Dependency structure in a \acrshort{ssm} as given by \Cref{def:ssm}. The dependencies between observations $Y_{t-1}$ (indicated by dotted arrows) are usually not part of the standard definition of a \acrshort{ssm}, but can be incorporated in a straightforward manner.}
    \label{fig:ssm_dependencies}
\end{figure}


Given data $y = (y_t)_{t = 0, \dots, n}$ that may be modeled with a \gls{ssm} the practitioner is confronted with several tasks, which provide the structure of this chapter:

\begin{enumerate}
    \item\label{it:model_choice} Choosing a suitable, usually parametric, class of \glspl{ssm} that include the effects of interest.
    \item\label{it:model_fitting} Fitting such a parametric model to the data at hand by either frequentist or Bayesian techniques.
    \item\label{it:smoothing_problem} Infer the latent states $X$ from the observations by determining, either analytically or through simulation, the smoothing distribution $X|Y$.
\end{enumerate}

The first step, \cref{it:model_choice}, requires that the practitioner specifies a joint probability distribution for the states and observations (see \Cref{cha:analysis_of_selected_models} for examples of this).
Due to the assumed dependency structure, this boils down to specifying transition kernels for the states and observations.
The setting given in \Cref{def:ssm} is too abstract to perform inference in, so further assumptions on the types of distributions for the latent states and observations are needed.
In this chapter, we will discuss \glspl{glssm}  (\Cref{sec:linear_gaussian_state_space_models}), where both the posterior distribution and the likelihood can be derived analytically. For the epidemiological application we have in mind, these are, however, insufficient due to the non-linear behavior of incidences and the low count per region (\Cref{sec:dessiderata}).
Such observations are better modeled with distributions on the natural numbers, i.e. with a Poisson or negative binomial distribution, both of which are exponential families of distributions. This will lead to the class of \acrfullpl{pgssm} (\Cref{sec:logconcave_gaussian_state_space_models}) which will become the main focus of our study.

Regarding the second step, \cref{it:model_fitting}, a frequentist practitioner will want to perform maximum likelihood inference on $\theta$.
While asymptotic confidence intervals for the \gls{mle} $\hat\theta$ can be derived both theoretically and practically \citep[Chapter 7]{Durbin2012Time}, they are, in the context of this thesis, usually of little interest. For these asymptotic frequentist procedures to be meaningful, an appropriate central limit theorem must hold. However, as the time series we study are non-stationary and the dependence on parameters $\theta$ is allowed to be arbitrary, it is in general not obvious that such a theorem holds for the model under consideration. Instead, we approach this fitting as an Empirical Bayes procedure and our main practical interest lies in analyzing the posterior distribution $X|Y$ where we set $\theta$ equal to $\hat\theta$. 


To obtain the maximum likelihood estimates $\hat\theta$ one needs access to the likelihood
\begin{align}
    \label{eq:likelihood}
    p_{\theta}(y) = \int_{\mathcal X^{(n + 1)}} p_{\theta}(x,y) \d (\mu_{\mathcal X})^{(n+1)}x =\int_{\mathcal X^{(n + 1)}} p_{\theta}(x,y) \d x = \int_{\mathcal X^{(n + 1)}} p_{\theta}(y|x) p_{\theta}(x) \d x
\end{align}
which is usually not analytically available. Here and in the following we assume that $\mathcal X = \R^{m}$ for some $m \in \N$, that $p$ is absolutely continuous with respect to the $m$-dimensional Lebesgue measure and that $p$ is regular enough that the integral is a Riemann integral.
Direct numerical evaluation of \Cref{eq:likelihood} is hopeless due to the high dimensionality of the state space $\mathcal X^n$.
Instead, we will resort to simulation-based inference by importance sampling (see \Cref{sec:importance_sampling}), a Monte-Carlo method that approximates $p(y)$ by constructing a global tractable approximation to the integrand in \Cref{eq:likelihood}. Alternatively, \gls{smc} methods, i.e. particle filters, that perform importance sampling sequentially across the $n + 1$ time steps can be used. We will not follow this approach for reasons described later, but refer the reader to the excellent reference \citep{Chopin2020Introduction} for an introduction to these methods.

The performance of such simulation-based estimates depends crucially on our ability to construct distributions that are close to the posterior $p(x|y)$ but are easy to sample from. To this end, we construct either \acrfullpl{glssm} (\Cref{subsec:glssm-approach}) in which sampling from the posterior is analytically possible, or Gaussian Markov processes (\Cref{subsec:markov-approach}) which are directly amenable to simulation.
These two approaches are motivated by what we term ``{}optimal importance sampling''{}, where we use a proposal distribution that solves an optimization problem. Two popular approaches for choosing such a proposal are \acrlong{eis} and the \acrlong{cem}, which minimize an $L^{2}$ or \acrshort{kld} loss, respectively. Empirically, it has been shown that \acrshort{eis} outperforms the \acrshort{cem}, to which we add theoretical insight in the form of two central limit theorems (\Cref{sec:importance_sampling}): as both methods rely on importance sampling to determine an optimal proposal, the asymptotic variance of this procedure is of practical relevance, and we argue that this asymptotic variance is typically smaller for \acrshort{eis}.
To this end, we provide extensive simulation studies investigating the asymptotic variance of the two methods in \Cref{sec:simulation_studies}. 
To the best of the authors' knowledge, this is the first rigorous investigation comparing these two methods. 
%This will be a good strategy if the target posterior $p(x|y)$ can be well approximated by a Gaussian distribution --- otherwise, we may want to account for multiple modes by considering mixtures of Gaussian state space models or account for heavy tails with t-distributed errors (\Cref{sec:accouting_for_multimodality_and_heavy_tails}) \todo{keep this here?}.

Finally, \cref{it:smoothing_problem} concerns the actual inference of the latent states $X$ given observations $Y=y$, a classical problem in Bayesian inference. Except for the \acrshort{glssm} (\Cref{sec:linear_gaussian_state_space_models}), the posterior distribution $X|Y=y$ is usually not analytically tractable, and we have to resort to simulation-based methods. We favor importance sampling over \gls{mcmc} methods due to the ease of implementation and the possibility to parallelize the simulations.

As an alternative to the above, \acrshort{mle}-based approach, a fully Bayesian approach would regard $\theta$ as random and administer a prior distribution, say with density $p(\theta)$. In this setting, the main interest still lies in determining the posterior distribution of $X|Y=y$, but due to the prior put on $\theta$, its density, should it exist, is now given by
$$
p(x|y) = \int p(x,\theta|y) \d \theta,
$$
where $p(x,\theta|y)$ is the joint posterior of states and hyperparameters, conditional on observations $y$. To tackle this problem, one may again use importance sampling methods, see e.g. \citep[Chapter 13.1]{Durbin2012Time}, or use \acrshort{mcmc}-methods tailored to \acrshortpl{ssm}, e.g. Particle-\acrshort{mcmc} \citep[Chapter 16]{Chopin2020Introduction} --- however this approach is outside the scope of this thesis.


To perform the above tasks, the setting defined in \Cref{def:ssm} is too general to have numerically tractable solutions. Thus we restrict our studies to more structured \acrshortpl{ssm}. We begin with assuming a joint Gaussian distribution for states and observations. Subsequently, we will relax this assumption to allow the observations $Y$ to have more general distributions. 
%\input{chapters/03_state_space_models/03_01_Modelling.tex}
\input{chapters/03_state_space_models/03_02_LGSSM.tex}
\input{chapters/03_state_space_models/03_03_LCSSM.tex}
\input{chapters/03_state_space_models/03_04_IS.tex}
\input{chapters/03_state_space_models/03_05_comparison.tex}
\input{chapters/03_state_space_models/03_05_Gaussian_IS.tex}
%\input{chapters/03_06_multimodality_heavy_tails.tex}
\input{chapters/03_state_space_models/03_07_MLE.tex}
\input{chapters/03_state_space_models/03_08_comparison.tex}
\input{chapters/03_state_space_models/03_09_conclusion.tex}

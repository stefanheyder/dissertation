\section{Conclusion}
\label{sec:03_conclusion}

This chapter provides a comprehensive comparison of the \acrshort{cem} and \acrshort{eis}. Crucially, we provide the \acrshortpl{clt} \Cref{thm:cem-clt,thm:eis-clt} (\Cref{sec:importance_sampling}) and made the \acrshort{cem} feasible for state space models (\Cref{sec:gaussian_importance_sampling_for_state_space_models}). These theoretical insights facilitate the comparisons in \Cref{sec:simulation_studies}, allowing us to bridge the gap between communities that have, to the best of the authors' knowledge, developed separately from one another.

The main insight we can derive from the examples in \Cref{sec:simulation_studies} is that the main obstacle the \acrshort{cem} faces in applications is likely not that its optimal proposal is far away from the target, but rather that its asymptotic variance may be too large to facilitate fast finite-sample convergence. This in turn leads to proposals that are far away from the optimal one, which in high-dimensional settings results in poor importance sampling performance. As we have seen in \Cref{subsec:performance_at_optimal}, the efficiency factor at the optimal proposal is --- for most scenarios studied --- comparable between the \acrshort{cem} and \acrshort{eis}, as long as both methods are equipped with a sufficiently large sample size to ensure convergence. Additionally, in \Cref{fig:cem_eis_sigma2} we saw that \acrshort{eis} tends to produce proposals with larger variances. Following \Cref{lem:gaussian_proposal_factor_2} proposals with larger variance can be seen as preferable, as small variance may lead to inadmissible proposals.

Let us stress that the methods we used to obtain the two \acrshortpl{clt} can be applied to other methods that find optimal proposals, such as the \acrshort{vmm} or the recent neural importance sampling \citep{Muller2019Neural}, and can guide the choice of importance sampling methods in applications.

In total, we recommend using \acrshort{eis} over the \acrshort{cem} for the following reasons:
\begin{itemize}
    \item the asymptotic variance of \acrshort{eis} seems to be smaller, especially if the target is close to a Gaussian (\Cref{prop:eis-finite-sample}),
    \item \acrshort{eis} is computationally more efficient, as it can be implemented in terms of the efficient simulation smoother and can exploit structure of the linear signal, if it is present and
    \item the least-squares regression seems numerically stable and available in many numerical libraries.
\end{itemize}
\section{Maximum likelihood estimation in SSMs}
\label{sec:maximum_likelihood_estimation}

% region introduction
%% need for MLE: hyperparameters
Until now, we have assumed that the \acrshort{ssm} under consideration is completely known, i.e. we have access to the true transition and observation kernels. For the models considered in this thesis (\Cref{cha:analysis_of_selected_models}), this is unrealistic, as they are not based on concrete physical processes but are rather statistical approximations of the true underlying dynamics. The transition densities of, e.g., \Cref{eq:glssm_states} will depend on the covariance matrix of innovations, of which we have no a priori knowledge and for negative binomially distributed observations the overdispersion parameter $r$ will be unknown. Let us denote by $\theta\in\R^{l}$ the vector of these hyperparameters. \todo{check l / k with psis}
To make this dependence explicit, we will introduce subscripts $\theta$ where appropriate, i.e. $\P_{\theta}$ is a target distribution that additionally depends on $\theta$, $p_{\theta}$ its density et cetera. This section is loosely based on \citep[Chapter 7 \& 11]{Durbin2012Time} and \citep[Chapter 14]{Chopin2020Introduction}

To determine a suitable value of $\theta$, multiple options are available. Here, we opt for a frequentist approach, using maximum likelihood estimation to determine an optimal $\hat \theta$. Therefore, given observations $y\in\R^{(n+1)\times p}$, $\hat\theta$ maximizes the likelihood $p_{\theta}(y)$ and can be obtained as the global maximum of the following optimization problem: 
$$
    \max_{\theta \in \Theta} p_{\theta}(y).
$$
For numerical stability, we should maximize the log-likelihood instead, i.e. solve 
\begin{align}
    \label{eq:max-log-p}
    \max_{\theta \in \Theta} \log p_{\theta}(y).
\end{align}
Here $\Theta \subseteq \R^{l}$ is the parameter space. To solve this optimization problem using gradient ascent algorithms, we need access to both the likelihood and its derivatives. Thus, in the following, we will assume that $\theta \mapsto \log p_{\theta}(y)$ is sufficiently smooth, to apply these methods, i.e. it has continuous derivatives of second order. 

%% GLSSM analytically available, still need to use gradient descent algs. 
%% analytically impossible
%% high dimensional integral -> importance sampling
While the Kalman-filter (\Cref{alg:kalman_filter}) allows analytical computation of this likelihood \acrshortpl{glssm}, in general \acrshortpl{ssm} it is numerically intractable. The reason for this is that
$$
    p_{\theta}(y) = \int p_{\theta}(x,y) \mathrm d \mu(x)
$$
is a high-dimensional integral, which is hard to evaluate numerically. Instead, we will use importance sampling to estimate the likelihood. For this, let us regard $p_{\theta}(x,y)$ as an unnormalized density in $x$. The missing integration constant is then just $p_{\theta}(y)$ and the normalized density is $p_{\theta}(x|y)$. If $\G \gg \P$ is a proposal distribution whose density $g$ with respect to $\mu$ we can evaluate analytically, i.e. not only up to a constant, we see that for the unnormalized weights $\tilde w_{\theta}(x) = \frac{p_{\theta}(x,y)}{g(x)}$, that $p_{\theta}(y) = \G [\tilde w_{\theta}]$. Thus we may estimate the likelihood by 
$$
    \verywidehat{p_{\theta}(y)} = \frac{1}{N}\sum_{i = 1}^N \tilde w_{\theta} (X^{i})
$$
for $X^{1}, \dots, X^{N} \iid \G$ and $N \in \N$. To evaluate the gradient, notice that as $\nabla_{\theta} p_{\theta}(x,y) = p_{\theta}(x,y) \nabla_{\theta} \log p_{\theta}(x,y)$, we have, provided we can exchange integration and differentiation,
\begin{align*}
     \nabla_{\theta} p_{\theta}(y) &= \nabla_{\theta}\int p_{\theta}(x,y)\d \mu(x) = \int p_{\theta}(x,y) \nabla_{\theta} \log p_{\theta}(x,y)\d \mu(x) \\
     &= \G [\tilde w_{\theta} \nabla_{\theta} \log p_{\theta}(x,y)],
\end{align*}
and so we may estimate the gradient by 
\begin{align*}
    \verywidehat{\nabla_{\theta} p_{\theta}(y)} &= \frac{1}{N}\sum_{i = 1}^N \tilde w_{\theta}(X^{i}) \nabla_{\theta} \log p_{\theta}(X^{i}, y)
    %&= \sum_{i = 1}^N \tilde w_{\theta}(X^{i}) \sum_{t = 0}^n \nabla_{\theta} \left( \log p_{\theta}(y_{t} | X^{i}_{t}) + \log p_{\theta}(X^{i}_t|X^{i}_{t - 1}) \right).
\end{align*}
Similarly, we can estimate the log-likelihood by Plug-In
\begin{align}
    \label{eq:loglik-hat-standard}
    \verywidehat{\log p_{\theta}(y)} = \log \left( \frac{1}{N}\sum_{i = 1}^N \tilde w_{\theta}(X^{i}) \right)
\end{align}
and its gradient, using the fact that the gradient of $\log f$ for $f: \R^{l} \to \R$ is $ \frac{1}{f} \nabla_{\theta} f$, by 
\begin{align*}
    \verywidehat{\nabla_{\theta} \log p_{\theta}(y)} &= \left(\frac{1}{N} \sum_{i = 1}^N \tilde w_{\theta}(X^{i}) \right)^{-1} \left( \frac{1}{N}\sum_{i = 1}^N \tilde w_{\theta}(X^{i}) \nabla_{\theta} \log p_{\theta}(X^{i}, y) \right) \\
    &=\sum_{i = 1}^N W_{\theta}^{i} \nabla_{\theta} \log p_{\theta}(X^{i}, y)
\end{align*}
where $W_{\theta}^{i} = \frac{\tilde w_{\theta}(X^{i})}{\sum_{i= 1}^N \tilde w_{\theta}(X^{i})}$ are the auto-normalized weights.
Note that, by Jensen's inequality, these estimates are biased.


%% optimizatino using CRNs, advantage over particle filters
To solve the optimization problem \eqref{eq:max-log-p} we will again employ \acrshortpl{crn}. If the densities involved are twice differentiable, this device ensures that the random objective function $\theta \mapsto \sum_{i = 1}^N \tilde w_{\theta}(X^{i})$ is twice differentiable, and so we can indeed apply gradient ascent to find a local maximum. This is an advantage of performing global importance sampling over \acrshort{smc}, i.e. particle filter, methods. To avoid collapse to a single particle, \acrshort{smc} methods perform intermediate resampling steps, which make the objective function discontinuous. While particle smoothing methods can mitigate this problem, they are more expensive than standard \acrshort{smc} and, as the importance sampling estimates of the log-likelihood and its gradient are biased, the usual requirements for stochastic approximation methods are not fulfilled. 
For a more thorough discussion of the challenges maximum likelihood estimation with \acrshort{smc} methods faces, we recommend \citep[Chapter 14]{Chopin2020Introduction}.

%% discuss not really frequentist setting
While \acrshortpl{mle} have a strong frequentist foundation, let us stress that, for the models that we investigate in \Cref{cha:analysis_of_selected_models}, the frequentist properties of the estimates are not of interest. The reason for this is that a frequentist interpretation requires us to imagine, at least hypothetically, an infinite repetition of the data-generating process. For the data at hand, such repetition is nonsensical: the pandemic is a \glqq{}one-off\grqq{} event that will not be replicated under even approximately similar circumstances. Therefore, we will choose to view the estimation procedure more as a hyper-parameter tuning step, rather than true frequentist inference. While we can compute asymptotic confidence intervals for $\hat\theta$, see, e.g., \citep[Chapter 11.6]{Durbin2012Time}, \citep[Chapter 14.8]{Chopin2020Introduction}, these are not of practical interest for similar reasons. 

%% alternative: fully Bayesian
As an alternative to modeling $\theta$ as fixed, but unknown, and performing maximum-likelihood estimation to obtain $\hat \theta$, one might also model $\theta$ as random with prior density $p(\theta)$, such that the full model becomes $p(x,y,\theta) = p(x,y|\theta)p(\theta)$. In this setup, sometimes called the Bayesian treatment of \acrshortpl{ssm} \citep[Section 13.1]{Durbin2012Time}, the main interest still lies in the posterior density $p(x,\theta|y)$, which, depending on the model at hand, can drastically increase the difficulty of the problem: even if $p(x,y|\theta)$ is an analytically tractable model such as a \acrshort{glssm}, unless the prior is chosen to be conjugate, one has to resort to, e.g., \acrshort{mcmc}-methods. 

% endregion

% region GLSSM proposal

%% joint density easy to calculate
By the structure of the model, \Cref{eq:joint_density}, the log density and its gradient can be computed efficiently by
\begin{align*}
    \log p_{\theta}(x,y) &= \log p_{\theta}(x_{0}) + \sum_{t = 1}^{n} \log p_{\theta}(x_{t}|x_{t-1}) + \log p_{\theta} (y_{t}|x_{t},y_{t - 1})\\
    \nabla_{\theta}\log p_{\theta}(x,y) &= \nabla_{\theta}\log p_{\theta}(x_{0}) + \sum_{t = 1}^{n} \nabla_{\theta}\log p_{\theta}(x_{t}|x_{t-1}) + \nabla_{\theta}\log p_{\theta} (y_{t}|x_{t},y_{t - 1}),
\end{align*}
respectively. 

Similarly, when proposing with a \acrshort{glssm} or Markov-proposal for a \acrshort{pgssm}, the weights have similar structure, see\Cref{eq:weights_markov,eq:weights_only_on_signal}, which makes calculation of $\tilde w$ efficient. 

For the remainder of this section, let us consider the \acrshort{glssm}-proposal obtained by \acrshort{eis} for a \acrshort{pgssm} with linear signal, as this is the main setting of \Cref{cha:analysis_of_selected_models}. For this we obtain 
$$
    \tilde w_{\theta}(x) = \tilde w_{\theta}(s) g(z)\frac{p_{\theta}(y|s)}{g(z|s)} = g(z) \prod_{t = 0}^n \frac{p_{\theta}(y_{t}|s_{t})}{g(z_{t}|s_{t})},
$$
where $s_{t} = B_{t}x_{t}$, $t = 0, \dots, n$, is the signal, and so the log-likelihood is given by 
\begin{align}
    \label{eq:loglik-pgssm-exact}
    \log p_{\theta}(y) = \log g_{\theta}(z) + \log \E \left(w_{\theta}(S)|Y = y\right)
\end{align}
and can be estimated by
\begin{align}
    \label{eq:loglik-hat-linearsignal}
    \verywidehat{\log p_{\theta}(y)} = \log g_{\theta}(z) + \log \left(\frac{1}{N}\sum_{i=1}^{N}\prod_{t = 0}^{n} \frac{p_{\theta}(y_{t}|S^{i}_{t})}{ g(z_{t}|S^{i}_{t})}\right).
\end{align}
Notice that $\log g_{\theta}(z)$ is the likelihood in a \acrshort{glssm}, which can be computed efficiently by the standard Kalman filter (\Cref{alg:kalman_filter}). As in the \acrshort{glssm}-approach we propose with an \acrshort{glssm} whose state density $g(x)$ and observation matrices $B_{t}$, $t = 0, \dots, n$ are equal to those of the target, the log-likelihood $\log g_{\theta}(z)$ also depends on $\theta$. The estimated gradient of the log-likelihood is 
$$
    \verywidehat{\nabla_{\theta} \log p_{\theta}(y)} = \nabla_{\theta} \log g_{\theta}(z) + \sum_{i=1}^N W^{i}_\theta \sum_{t = 0}^n \nabla_{\theta} \log p_{\theta}(y_{t}|S_{t}^{i}).
$$
The gradient of the \acrshort{glssm} log-likelihood can be obtained either numerically or analytically by employing the Kalman filter and smoother \citep{Koopman1992Exact}, however, numerical evaluation may be faster if the dimension of $\theta$ is small compared to the length of the time series, as evaluating the likelihood only requires a single application of the Kalman filter. 

As the observation densities $g(z_{t}|s_{t})$ do not depend on $\theta$, their derivatives do not appear in the above estimate. However, when using \acrshort{eis} to determine an optimal proposal, the parameter $\psi = (z, \omega)$ implicitly depends on $\theta$. Accounting for this yields the gradient 
$$
    \verywidehat{\nabla_{\theta} \log p_{\theta}(y)} = \nabla_{\theta} \log g_{\theta}(z) + \sum_{i=1}^N W^{i}_\theta \left(\sum_{t = 0}^n \nabla_{\theta} \log p_{\theta}(y_{t}|S_{t}^{i}) - \nabla_{\theta} \log g_{\theta}(z_{t}|S^{i}_{t})\right),
$$
as $\nabla_{\theta} \frac{1}{g_{\theta}(z|s)} = - \frac{1}{g_{\theta}(z|s)} \nabla_{\theta} \log g_{\theta}(z|s)$. The computation of this additional term is much more involved, as the parameters $z,\Omega$ are found through an iterative numerical scheme. Instead, we favor numerical differentiation of the whole procedure to evaluate the likelihood at $\theta$, including the method of finding an optimal importance sampling scheme. 


As a single evaluation of the log-likelihood can become very expensive we want our procedure to be as efficient as possible. To this end, \citep{Durbin1997Monte} provides several improvements to the basic algorithm if the model is a \acrshort{pgssm} with a linear signal. Their contributions consist of a bias correction for the log-likelihood, the use of antithetic and control variables to reduce Monte-Carlo error for importance sampling and a deterministic initialization procedure.
Let us briefly summarize these ideas, adapted to our notation. As the computational gains for control variates in the presence of antithetic variables seem to be limited, we do not give the same level of detail here, for an in-depth analysis, we refer the reader to the source. 

% bias reduction
For bias reduction, a second-order Taylor series expansion shows that for $\tilde{w}_\cdot = \frac{1}{N} \sum_{i =1}^N \tilde w(X^{i})$,
\begin{align*}
    \E \left(\log \tilde{w}_\cdot\right) - \log \G \tilde w &= \E \log \left(1 + \frac{\tilde{w}_\cdot - \G \tilde w}{\G \tilde w} \right)\\
                                                           &=  \frac{\tilde{w}_\cdot - \G \tilde w}{\G \tilde w}  - \frac{1}{2} \left(\frac{\tilde{w}_\cdot - \G \tilde w}{\G \tilde w} \right)^{2} + \mathcal O_{p}(N^{-\frac{3}{2}}),
\end{align*}
provided $\tilde w \in L^{3}(\G)$. Thus, estimating the second order term by $- \frac{\hat\sigma^2}{2N \tilde{w}_\cdot} $, where $\hat \sigma^{2}$ is the empirical variance of the unnormalized weights, we can perform a bias reduction by estimating 
\begin{align}
    \label{eq:loglik-hat-bias-reduction}
    \widehat{\log p_{\theta}(y)} = \log \left(\tilde w_{\cdot}\right) + \log g_{\theta}(z) + \frac{\hat\sigma^{2}}{2N\tilde w_{\cdot}}
\end{align}

% antithetics
The second improvement of \citep{Durbin1997Monte} is the use of antithetic variables and control variates, a device to reduce Monte-Carlo variance. The main idea of an antithetic variable is to construct for each sample $X^{i}$, $i = 1,\dots, N$, another sample $\tilde X^{i}$ that has the same distribution as $X^{i}$, but is negatively correlated with $X^{i}$. This has two effects: first of all, we increase the number of samples used for importance sampling and second, as the new samples are negatively correlated with the old samples, the Monte-Carlo variance is reduced. The computation of these samples is usually much faster than creating new samples, which requires the use of the expensive \acrshort{ffbs} or simulation smoother algorithms. 
\begin{definition}[antithetic variable]
    Let $X, \tilde X\in\R^{k}$ be two random variables with the same distribution, $\mathcal L (X) = \mathcal L(\tilde X)$ and $f: \R^{k} \to \R$. Then $\tilde X$ is called an antithetic variable of $X$ for $f$, if $\cov \left( f(\tilde X), f(X) \right) < 0$. If $k = 1$ and $f$ is the identity, we just say that $\tilde X$ is an antithetic variable of $X$.
\end{definition}

% location & scale
\citep{Durbin1997Monte} introduce two antithetic variables: balanced for location and balanced for scale, both of which are tailored to the multivariate normal distribution. 
\begin{definition}[antithetic variable balanced for location and scale, \citep{Durbin1997Monte}]
    Let $X\sim \mathcal N(\mu, \Sigma)$ for $\mu \in \R^{k}$ and $\Sigma \in \R^{k\times k}$ positive definite. We call
    \begin{align}
        \label{eq:antithetic-location}
    \tilde X = \mu + (\mu - X)
    \end{align}
    the antithetic balanced for location. If $L\in\R^{k\times k}$ is a Cholesky root of $\Sigma$ and 
    $$
        X = \mu + L \varepsilon
    $$
    with $\varepsilon \sim \mathcal N(0, I)$, let $c = \varepsilon^{T}\varepsilon \sim \chi^{2}_k$ and $c' = F^{-1}_{\chi^{2}_{k}}(1 - F_{\chi^{2}_k}(\sqrt{c}))$. We call
    \begin{align}
        \label{eq:antithetic-scale}
        \check X = \mu + \sqrt{\frac{c'}{c}} \left( X - \mu \right)
    \end{align}
    the antithetic balanced for location.
\end{definition}
\begin{lemma}
    In the above definition, $\tilde X_{i}$ is an antithetic variable of $X$ for the coordinate functions $f_{i}:\R^{k} \to \R$, $f_{i}(x) = x_{i}$, $i = 1, \dots, k$.
    Furthermore, $\tilde c$ is an antithetic variable of $c$.
\end{lemma}
\begin{proof}
    It is easy to see that $\tilde X$ has the same distribution as $X$. Furthermore 
    $$
        \cov \left( f_{i}(X), f_{i}(\tilde X)\right) = \cov \left( 2 \mu_{i} - X_{i}, X_{i} \right) = - \Sigma_{i,i} < 0.
    $$

    For $c$ and $\tilde c$, let $U = F_{\chi^{2}_{k}}(c)$, then $U \sim \operatorname{Unif}(0,1)$ and $\tilde U = 1 - U = F_{\chi^{2}_k}(\tilde c)$. 
    As $\tilde U \sim \operatorname{Unif}(0, 1)$ as well, $\mathcal L (c) = \mathcal L (\tilde c)$.
    In \citep[Lemma 2.3]{Whitt1976Bivariate} it is shown that for any pair of real-valued random variables $(Y,W)$ with CDF $H$ and marginal CDFs $F, G$, it holds
    $$
        \cov \left(Y,W \right) = \int_{\R^{2}} H(y,w) - F(y)G(w) \d y \d w,
    $$
    and, furthermore, by \citep[Theorem 2.1 and Lemma 2.4]{Whitt1976Bivariate} that the joint CDF of $(c, \tilde c)$ is $(y,w) \mapsto \max \{0, F(y) + G(w) - 1\}$, where $F$ is the CDF of $c$ and $G$ the CDF of $\tilde c$. 
    As 
    $$
        a + b - 1 = ab + a(1-b) + b - 1 = ab - (1 - a)(1 - b) < ab
    $$
    for all $a,b \in (0,1)$, we have 
    \begin{align*}
        \cov \left( c, \tilde c \right) &= \int_{\R^{2}} H(y,w) - F(y)G(w) \d y \d w \\
        &= \int_{\R^{2}} \max\{0, F(y) + G(w) - 1\} - F(y)G(w) \d y \d w < 0.
    \end{align*}
\end{proof}
Let us mention that, by the properties of the standard multivariate normal distribution, $ c = \lVert u \rVert $ and $ \frac{u}{ \lVert u \rVert }$ are independent. Writing 
$$
    X = \mu + \lVert u \rVert L \frac{u}{ \lVert u \rVert } = \mu + \lVert u \rVert \frac{X - \mu}{\sqrt{c}},
$$
we see that 
$$
    \check X = \mu + \sqrt{\tilde c}\frac{X - \mu}{\sqrt{c}}
$$
has the same distribution as $X$, as $\tilde c \sim \mathcal L( \lVert u \rVert^{2})$ and is independent of $ \frac{X - \mu}{\sqrt{c}}$. 

Given a \acrshort{glssm}-proposal and samples $X^{1}, \dots, X^{N}$ from it, we can cheaply calculate these antithetic variables: for the location balanced antithetic we can calculate the mean using the Kalman-smoother and for the scale balanced antithetic we can calculate $c$ and $c'$ using the inverse CDF of the $\chi^{2}_{k}$ distribution and the standard normal samples used to sample $X^{i}$ in the first place, for which fast implementations are readily available. Incidental, we obtain a third antithetic, 
\begin{align}
    \label{eq:antithetic-scale-location}
    \breve{X} = \mu - \sqrt{ \frac{c'}{c}} (X - \mu)
\end{align}
for free. We can then estimate the log-likelihood in \Cref{eq:loglik-hat-bias-reduction} by replacing each occurrence of $\tilde w_{\theta}(X^{i})$ by 
\begin{align}
    \label{eq:antithetic-weights}
    \frac{1}{4} \left( \tilde w_{\theta} (X^{i}) + \tilde w_{\theta}(\tilde{X^{i}}) + \tilde w_{\theta}(\check{X^{i}}) + \tilde w_{\theta}(\breve{{X^{i}}}) \right).
\end{align}



% intialization
As the procedure to evaluate the likelihood by importance sampling becomes expensive as the dimension of the model increases, \citep{Durbin1997Monte} recommend finding an initial value $\hat \theta_{0}$ by maximizing a deterministic version of \Cref{eq:loglik-hat-standard}. For this, denote by $s^{\ast}$ the mode of the linear signal, conditional on the pseudo-observations $z$. As $S$ follows a multivariate Gaussian, $s^{\ast}$ is also the mean which can be computed efficiently by the Kalman or signal-smoother. Approximating the conditional expectation in \Cref{eq:loglik-pgssm-exact} by $w_{\theta}(s^{\ast})$ then yields 
\begin{align}
    \label{eq:loglik-initial-approx-mode}
    \log p_{\theta}(y) \approx \log g_{\theta}(z) + \log w_{\theta}(s^{\ast}),
\end{align}
which can be evaluated without simulation by the \acrshort{la}. A better approximation can be obtained by performing a fourth-order Taylor expansion of $s\mapsto w_{\theta}(s)$ around the mode $s^\ast$, which yields 
\begin{align}
    \label{eq:loglik-initial-tayolor-approx-mode}
    \log p_{\theta}(y) \approx \log g_{\theta}(z) + \log w_{\theta}(s^{\ast}) + \log \left( 1 + \frac{1}{8} \sum_{t = 1}^n\sum_{j = 1}^m l^{(4)}_{t,j}(s^{\ast}) v_{t,j}^2 \right),
\end{align}
where $l^{(4)}$ is the fourth derivative of the log-weights $s\mapsto \log w_{\theta}(s)$ and $v_{t,j}$ is the conditional variance $\var \left( S_{t,j} | Z = z \right)$ in the proposal. Again, we refer the interested reader to the source for the details.

% endregion
\begin{algorithm}
    \label{alg:mle}
    \begin{algorithmic}[1]
        \Require parameterized \acrshort{pgssm} with linear signal, initial $\theta^{0} \in \Theta$, observations $y \in \R^{(n+1)p}$, number of samples $N$
        % initialization
        \Function{approx\_loglik}{$\theta$}
            \State obtain \acrshort{la} of the \acrshort{pgssm} for $\theta$ \Comment{\Cref{alg:la}}
            \State obtain mode $s^{\ast}$ and conditional variances $v_{t,j}$ from the \acrshort{la} \Comment{\Cref{alg:kalman_filter,alg:kalman_smoother}}
            \State \textbf{return} approximate log-likelihood \Comment{\Cref{eq:loglik-initial-approx-mode} or \Cref{eq:loglik-initial-tayolor-approx-mode}}
        \EndFunction 
        \Statex

        \Function{estimate\_loglik}{$\theta$}
            \State obtain \acrshort{la} of the \acrshort{pgssm} for $\theta$ \Comment{\Cref{alg:la}}
            \State obtain \acrshort{eis} proposal $\G_{(z,\Omega)}$ \Comment{\Cref{alg:eis}, \acrshort{la} as initial values}
            \State sample $N$ signals $S^{i}$ from $S|Z = z$ in \acrshort{eis} \Comment{\Cref{alg:ffbs} or signal smoother}
            \State obtain mode $s^{\ast}$ in \acrshort{eis} proposal \Comment{\Cref{alg:kalman_smoother} or signal smoother}
            \State calculate antithetic variables $\tilde{S^{i}},\check{S^{i}}, \breve{{S^{i}}}$ \Comment{\Cref{eq:antithetic-location,eq:antithetic-scale,eq:antithetic-scale-location}}
            \State set $\tilde w_{\theta}^i = \frac{1}{4} \left( \tilde w_{\theta} (X^{i}) + \tilde w_{\theta}(\tilde{X^{i}}) + \tilde w_{\theta}(\check{X^{i}}) + \tilde w_{\theta}(\breve{{X^{i}}}) \right)$ \Cref{eq:antithetic-weights}
            \State set $\tilde w_{\cdot} = \frac{1}{N}\sum_{i = 1}^N \tilde w^{i}_{\theta}$
            \State set $\hat \sigma^{2} = \frac{1}{N - 1} \sum_{i = 1}^N \left( \tilde w_{\theta}^{i} - \tilde w_{\cdot}\right)^{2}$
            \State calculate $\log g_{\theta}(z)$ \Comment{\Cref{alg:kalman_filter}}
            \State \textbf{return} $\verywidehat{\log p_{\theta}(y)}$ \Comment{\Cref{eq:loglik-hat-bias-reduction}}
        \EndFunction
        \Statex

        \State maximize \textrm{APPROX\_LOGLIK} with initial value $\theta^{0}$  \Comment{numerically}
        \State set $\theta^{0} $ to optimal value
        \State maximize \textrm{ESTIMATE\_LOGLIK} with initial value $\theta^{0}$ and \acrshortpl{crn}  \Comment{numerically}
        \State set $\hat \theta$ to optimal value
        \State \textbf{return} $\hat \theta $
    \end{algorithmic}
    \caption{Maximum likelihood estimation in a \acrshort{pgssm} with linear signal using \acrshort{eis}.}
\end{algorithm}

The resulting procedure to find the MLE $\hat \theta$ in a \acrshort{pgssm} with linear signal is summarized in \Cref{alg:mle}. Notice that we use \acrshortpl{crn} to ensure numerical convergence. The numerical optimization can be performed using any standard solver such as the BFGS algorithm \citep[Chapter 6.1]{Nocedal2006Numerical}. We cannot give guarantees that this procedure produces the true \acrshort{mle}, i.e. finds the global maximizer. However, as we have discussed earlier, we are not interested in frequentist properties of $\hat \theta$ but see the estimation procedure as a hyperparameter tuning step. Thus, a local maximum may well be sufficient. Nevertheless, checking different starting points and random number seeds should be used to get as close as possible to the global maximum.

% region outlook
Notice that our discussion implies that we cannot reuse a \acrshort{glssm} proposal used for $\theta$ at another $\theta'$, as $p_{\theta'}(x) \neq g_{\theta}(x)$. While we can still calculate the weights using the general \Cref{eq:loglik-hat-standard}, we presume that the old proposal is not a good choice for the new target. The reason for this is that $\theta$ will usually contain parameters related to the covariance structure of the innovations and observations, and these parameters usually affect many, if not all states or observations. For example, it is common to model states that perform a random walk with common innovation variance $\sigma^{2}$ as an element of $\theta$. As the distributions lie in a high-dimensional space, slight misspecification of the covariance structure will drastically deteriorate the performance of importance sampling. 

If computations are so involved that we want to avoid running the optimal importance sampling scheme as much as possible, one could try, if the model under investigation allows for it, to split $\theta$ into $(\theta_{x}, \theta_y)$ where $\theta_{x}$ only affects the state transitions and $\theta_{y}$ only affects the observation densities. Then a coordinate ascent scheme could be employed, where the update step for $\theta_{y}$ can reuse the proposal, provided that $\theta_{y}$ does not change too much and the observation density $p_{\theta}(y|x)$ is not too sensitive to changes in $\theta_{y}$, which should imply that the proposal is still close enough to give good importance sampling performance. Then numerical differentiation is only required to update $\theta_{x}$. 

% endregion

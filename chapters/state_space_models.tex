\chapter{State Space Models}
\label{chapt:ssm}

State space models ...


\begin{definition}[State Space Model]
    \label{def:ssm}
    A \textbf{state space model} is a discrete time stochastic process $(X_t, Y_t)_{t=0, \dots, n -1}$ taking values in $\mathcal X \times \mathcal Y$ such that
    \begin{enumerate}
        \item The marginal distribution of the \textbf{states} $(X_0, \dots, X_{n - 1})$ is a discrete time Markov process, i.e. if $s <t$ then $X_t$ is conditionally independent of $X_s$ given $X_{t - 1}$.
        \item Conditional on the state $X_t$ and observation $Y_{t - 1}$, $Y_t$ is independent of $X_s$ and $Y_{s - 1}$, $s < t$.
    \end{enumerate}
\end{definition}

For notational convenience we will write $\X_{s:t} = \left(X_s, \dots, X_{t}\right)$ for the vector that contains all states from $s$ to $t$, dropping the index $s:t$ if we consider the whole set of observations, so $\X = \X_{0:n-1}$ 
Similarly we set $\Y_{s:t} = \left(Y_s, \dots, Y_{t}\right)$ and $\Y = \Y_{0:n-1}$.


\todo{picutre of dependency structure}

\begin{remark}
    Contrary to the standard definition of a state space model, our \Cref{def:ssm} allows $Y_t$ to depend on $Y_{t - 1}$.
    This is not a limitation of the standard definition: given a state space model of the form in \Cref{def:ssm} we can transform it to the standard form by choosing states $(X_t, Y_t) \in \mathcal X \times \mathcal Y$ and observations $Y_t \in \mathcal Y$ such that the state space model becomes a stochastic process on $ \left( \mathcal X \times \mathcal Y\right) \times \mathcal Y$.
    As \Cref{chapt:epi_ssm} will make extensive use of state space models with this dependency structure we opt to use this non-standard definition here.

    In most models I consider in this thesis I will use $\mathcal X = \R^m$, $\mathcal Y = \R^p$ or $\mathcal Y = \Z^p$ so that $\mathcal X$ is $m$ dimensional and $\mathcal Y$ is $p$ dimensional.
\end{remark}

Given data $(y_t)_{t = 0, \dots, n - 1}$ that may be modeled with a state space model the practitioner is confronted with several tasks:

\begin{enumerate}
    \item\label{it:model_choice} Choosing a suitable, usually parametric, class of state space models that include the effects of interest.
    \item\label{it:model_fitting} Fitting such a parametric model to the data at hand by either frequentist or bayesian techniques.
    \item\label{it:smoothing_problem} Infer about the latent states $(X_0, \dots, X_{n-1})$ from the observations by determining, either analytically or through simulation, the \textbf{smoothing distribution} $\X|\Y$ or various functionals thereof.
\end{enumerate}


The first step, \cref{it:model_choice}, requires that the practitioner to specfiy a joint probability distribution for the states and observations.
Due to the assumed dependency structure this boils down to specifying transition kernels for the states and observations
\todo{ausfÃ¼hrlicher}. 

Most models that I consider in this thesis will admit densities for the state transitions w.r.t. a common dominating measure $\mu_{\mathcal X}$ and similar for the observations w.r.t. a (potentially different) domination measure $\mu_{\mathcal Y}$. \todo{check whether there are models that violate this} 

\begin{notation}[Densities, conditional densities]
    I will use the standard abuse of notation for densities that makes the type of density `obvious' from the arguments used.
    This means that $p(x)$ is the density for all states $\X$, $p(x_t|x_{t - 1})$ the conditional density of $X_t|X_{t - 1}$ and similaryl for 
    observations: $p(y|x)$ is the density of all observations $\Y$ conditional on all states $\X$.

    Note that this notation also implicitly includes the time $t$ and allows for changes in, \eg, the state transition over time.

    When densities stem from a parametric model parametrized by $\theta \in \Theta$ and the dependence of the model on $\theta$ is of interest I indicate this by adding a subscript to the densities.
    If the dependence is not of interest, \eg because $\theta$ is fixed, I will usually omit $\theta$ for better readability.

    In this notation the joint density of a parametric state space model factorizes as
    \begin{align*}
        p_\theta(x,y) &= p_\theta(x_0, \dots, x_{n - 1}, y_0, \dots, y_{n - 1}) \\
        &= p(_\theta x_0)\prod_{t = 1}^{n - 1} p_\theta(x_{t}|x_{t - 1}) \prod_{t = 0}^{n - 1} p_\theta(y_t | x_t, y_{t - 1}),
    \end{align*}
    where $p_\theta(y_0|x_0, y_{-1}) = p_\theta(y_0, x_0)$. 

\end{notation}
    
Refer to \Cref{chapt:epi_ssm} for constructing parametric state space models that capture relevant epidemiological effects.

Regarding the second step, \cref{it:model_fitting}, a frequentist practitioner will want to perform maximum likelihood inference on $\theta$.
While confidence intervals for $\theta$ can be derived both theoretically and practically, they are usually of little interest \todo{cite chopin?}.

To obtain maximum likelihood estimates $\hat\theta$ one needs access to the likelihood 
\begin{align}
    \label{eq:likelihood}
    p(y) = \int_{\mathcal X^n} p(x,y) \d x,
\end{align}
which is not analytically available except in special models (see \Cref{sec:lgssm}).
Direct numerical evaluation of \Cref{eq:likelihood} is usually hopeless due to the high dimensionality of the state space $\mathcal X^n$. 
Instead one resorts to simulation based inference by importance sampling (see \Cref{sec:is_for_ssm}) or particle filters \todo{cite something}.

\section{Linear Gaussian State Space Models}
\label{sec:lgssm}

\section{Importance Sampling for State Space Models}
\label{sec:is_for_ssm}

As the likelihood of a general state space model is neither analytically nor numerically tractable one has to resort to Monte-Carlo techniques.
Recall that the likelihood is a high-dimensional integral of the form
\begin{align*}
    \lik(\theta) = p_\theta(y) = \int p_\theta(y,x) \d x = \int p_\theta(y|x) p_\theta(x) \d x = \E p_\theta(y|X).
\end{align*}
By the standard law of large numbers we can approximate $\lik(\theta)$ by 
\begin{align*}
  \hat\lik(\theta) = \frac 1 N \sum_{i=1}^N p_\theta(y|X^i)  
\end{align*}
for $N\in\N$ samples $X^i \iid p(x)$. 
However, the variance of $\hat\lik(\theta)$ is likely to be very high if samples $X^i$ are drawn from the prior distribution $p(x)$ as they are not informed by the observations $y$. 
As $p_\theta(x|y) \propto p_\theta(x,y)$ a more promising approach would be to use samples $X^i \sim p_\theta(x|y)$, but this distribution is usually not available. 

While bayesian computational approaches such as MCMC\todo{cite} are able to generate (approximate) samples from this posterior distribution, importance sampling tries to find a distribution close to the target and re-weighs samples to ensure unbiased estimates of $\lik(\theta)$.

In more general terms, let $g: \mathcal X \to \R$ be a function whose integral $$\zeta = \int_{\mathcal X} g(x) \d x$$ we want to compute. 
Furthermore suppose that we can write 
$$
    \int_{\mathcal X} g(x) \d x = \int_{\mathcal X} f(x) \d \P(x)
$$
for a probability measure $\P$ and function $f: \mathcal X \to \R$. 
Let $\Q$ be another measure on $\mathcal X$ such that $f\P$ is absolutely continuous w.r.t. $\Q$, $f\P \ll \Q$.
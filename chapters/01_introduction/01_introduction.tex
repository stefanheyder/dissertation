\chapter{Introduction}
\label{cha:introduction}

% COVID-19 need for insight into spread, morbidity and mortality
The \gls{c19} pandemic put the scientific community to the test: How infectious, morbid, and mortal was the disease? When and for how long did infected people become infectious? How effective are the countermeasures taken? How safe and effective are the vaccines that were developed at an unprecedented speed? Some of these questions, such as those about the epidemiology of \acrshort{c19}, are confined to well-established areas of research, while others, e.g. those about the efficacy of countermeasures, required collaboration across a wide range of disciplines --- from infectious disease epidemiology, mathematical and statistical modeling, social and communication science, to non-scientific actors such as legislators, journalists and politicians.

% much data, need for knowledge 
Although there is still a significant amount of scientific and societal follow-up work to be done, given the magnitude of this challenge, it is astonishing how well the scientific community and society as a whole have dealt with the pandemic. A key factor in this accomplishment is the large-scale availability of data surrounding the pandemic. In many countries, including Germany, data on reported cases, deaths, vaccinations, and deaths were published daily by the respective national health authorities, which for Germany is the \gls{rki} \citep{RobertKoch-Institut2022SARSCoV2,RobertKoch-Institut2021COVID19Hospitalisierungen}.
%Additionally, mobility data from mobile communications providers allowed researchers to relate human movement to the spread of \acrshort{c19} \citep{Kraemer2020Effect,Schlosser2020COVID19}. 
As the news chronicled daily on the number of reported cases and deaths, numerous dashboards with analyses of \acrshort{c19} data were made available and an abundant number of scientific works were created. Effectively communicating with the public, whose cooperation with countermeasures was critical, became increasingly important. To disseminate insights to the public, we need to understand and communicate the underlying dynamics of an epidemic.

% pandemic is inherently a random phenomenon
% while large scale dynamics may be well approx. by det. systems,
% small scale require precise modelling
An epidemic outbreak is inherently a random phenomenon \citep{Diekmann2013Mathematical}. Who becomes infected, how long they stay infectious, whom they meet while they are infectious and whom they ultimately infect are all aspects that depend to a certain degree on chance. If one is interested in large-scale phenomena, e.g. effects of immunization in a large population, one relies on a deterministic model \citep{Britton2019Stochastic}, such as the classical S(E)IR model \citep{Kermack1927Contribution} or its variants. However, as soon as one is interested in more detailed phenomena, as we are in this thesis, stochastic and statistical modeling becomes essential. 

As statisticians, having access to vast amounts of data is both a blessing and a curse. While more, and ideally better, data enables us to formulate and address more relevant questions, the models we create to accommodate these data become increasingly complex. A major complexity of epidemic models are the dependencies across time, requiring the use of methods from time-series analysis. However, such models require more care in modeling, fitting, and interpretation, as there are more opportunities for error along the way. As we incorporate more detailed effects into our models, fitting the models to data becomes difficult to practically impossible using established techniques. While there are some remedies for this curse of dimensionality, e.g. exploiting as much available structure as possible, there is an ongoing need for new procedures enabling inference in these settings. As of the writing of this thesis, there is no comprehensive framework for creating such models that details how to incorporate the various phenomena practitioners are interested in. Additionally, we need both mathematical and practical insight into the performance of these procedures to make informed decisions in applied settings: which methods should we prefer under which circumstances?

These considerations set the stage for this thesis. Driven by the need for good statistical models that allow us to answer urgent questions in infectious disease epidemiology, with \acrshort{c19} as a prime example, we will start in \Cref{chap:epidemiological_considerations} with an analysis of what is required of these sought-after models. We will define and discuss the role of several epidemiological indicators, namely quantities that have an interpretation related to the epidemic. It turns out that we will usually be interested in quantifying the speed at which the epidemic proliferates, and we discuss several popular indicators that measure this speed. A useful statistical analysis should provide interpretable insight into the problem at hand, so we focus on how straightforward this interpretation is, offering recommendations on when to use which indicator. To estimate these indicators from data, we must create statistical models that include them. Before we do so, we will compile a list of desiderata from the context of \acrshort{c19} to identify a suitable class of such models. 

Many of these desiderata can be modeled by \acrlongpl{ssm}, a flexible framework for modeling non-stationary time series. Unfortunately, we will require that these \acrshortpl{ssm} include integer-valued, non-Gaussian, observations, which makes fitting the models to data analytically impossible and numerically difficult, as one is faced with an intractable high-dimensional distribution; similar to challenges arising in Bayesian inference. Instead of analytical derivations, inference will have to rely on simulation methods, most notably importance sampling. This is at the heart of \Cref{cha:state_space_models}. To apply these methods, the practitioner has some flexibility in the so-called proposal distribution, a tractable approximation to the sought-after distribution. Different disciplines have developed simulation-based techniques that allow the user to choose optimal proposals, where optimality is based on different performance criteria for different methods. In this thesis, we focus on two methods: the \gls{cem} and \gls{eis}, corresponding to \acrlong{kld} and least-squares loss respectively. In the literature, a comparison between these two methods is missing: there are neither mathematical nor empirical results comparing the two. We fill this gap by first proving central limit theorems for both methods, allowing for a theoretical comparison. Additionally, we provide extensive simulation studies comparing the methods on instructive univariate and \acrshortpl{ssm} examples. To this end, we also develop a new algorithm that allows the \acrshort{cem} to be applied to \glspl{ssm}. 

Finally, we demonstrate in \Cref{cha:state_space_models} how to solve a selection of infectious disease epidemiology problems using the mathematical insights we have gained. These examples focus on the \acrshort{c19} epidemic in Germany and illustrate the modeling, computational, and applied aspects of this thesis. We focus on the following three challenges by providing models and insights for German data: How does one model and account for the complex and artifact-prone reporting process of incident cases? How does one incorporate cross-regional infections into these models? And, finally, how does one account for the long reporting delays present in hospitalizations?

In summary, this thesis contributes to both theoretical and applied problems in the context of statistical modeling of infectious diseases. 
We hope that its results will enhance our ability to respond to future epidemic outbreaks.
\section{Removing reporting delays and weekday effects}%
\label{sec:model_reporting_delay}

Retrospective analysis of reported cases is one of the fundamental tasks in epidemiological monitoring (see \Cref{sec:objectives}). Such analyses require the finest temporal resolution possible to link changes in the epidemics spread to concrete dates, e.g. the enforcement of \acrshortpl{npi}. However, as we have demonstrated in \Cref{sec:data}, the available data are contaminated by the reporting process, most notably the weekday effects, reporting delays, and reporting artifacts associated with events such as public holidays.

While aggregation to the weekly level can mitigate these distortions, see \Cref{sec:regional_growth_factor_model}, modeling on the daily level facilitates better retrospective analyses and as such it is the goal of this section.

Here, we use the previously described \acrshort{rki} case incidence data discussed in \Cref{sec:data}. As demonstrated in \Cref{fig:reporting_delays_cases} \textbf{A} and \Cref{fig:survival_function_rep_tri_incidences}, most delays are fewer than $4$ days. Therefore, ignoring any cases reported with longer delays, we obtain for any reporting date $t$ four observations, which we denote by 
$$
    Y_{t} = \left( Y_{t, 1}, \dots, Y_{t, 4} \right) \in \N^{4}_{0}.
$$
Here $Y_{t,\tau}$, $\tau = 1, \dots, 4$, is the number of newly reported cases for reporting date $t$ with delay $\tau$, such that $Y_{t,\cdot} = \sum_{\tau = 1}^4 Y_{t, \tau}$ is the total number of cases reported for reporting date $t$ with delay $\leq 4$. 
Let $\hat p_{t, \tau} = \frac{Y_{t,\tau}}{Y_{t,\cdot}}$ denote the empirical delay probability for day $t$ with delay $\tau$. We have already observed in \Cref{fig:reporting_delays_cases} that $Y_{t, \cdot}$ is subject to weekday effects, and analogous to hospitalizations (\Cref{fig:double_weekday_effect_hosp}), there is small variation across weekdays of $\hat p_{t,\tau}$, especially if $t$ or $t+\tau$ falls on a weekend, as shown in \Cref{fig:weekday_effect_delays}. 

\begin{figure}
    \resizebox{\textwidth}{!}{%
        \input{tikz/weekday_effect_delays}%
    }
    \caption{Box plots of delay probabilities $\hat p_{t,\tau}$ by weekday of case reporting date $t$. As there are systematically fewer cases reported on Sunday, there is a small weekday effect: $p_{t,1}$ for Saturdays, $p_{t,2}$ for Fridays, $p_{t,3}$ for Thursdays and $p_{t,4}$ for Wednesdays are small compared to other days.}
    \label{fig:weekday_effect_delays}
\end{figure}

To produce accurate retrospective analyses of the daily growth factor, we will construct a \acrshort{ssm} that accounts for these delays, weekday effects and epidemics' dynamics. This model will enable us to better understand the delay process, accommodate periods of inconsistent reporting, and generate daily growth factors useful for the interpretation of \acrshort{npi} efficacy.

\todo{lit rev.}
The problem of accounting for reporting delays is generally termed ``{}nowcasting''{} in the literature, see also \Cref{sec:nowcasting_hospitalizations} and the literature review therein. Here, however, we are interested in a different problem: that of reconstructing the actual course of the epidemic, i.e. removing both the reporting delay and weekday-effects.

In addition, we will demonstrate the model's utility when handling reporting artifacts not explicitly modeled, e.g. the Christmas period of 2020. \Acrshortpl{ssm} handle missing data seamlessly, so removing observations in that period and fitting the model again is straightforward.

\subsection{Model}

To model the development of cases over time, we start with the exponential growth equation \Cref{eq:exponential-growth-time-varying}. Let $I_{t}$ be the total number of cases for reporting date $t$, unaffected by weekday effects and reporting delays. Ignoring variation around the mean, the exponential growth ansatz gives 
$$
    \log I_{t + 1} \approx \log \rho_{t + 1}  + \log I_{t}
$$
for the growth factor $\rho_{t}$ on day $t$. It is then sensible to assume that the growth factor $\rho_{t}$ performs a random walk on the log-scale, as we would expect large day-to-day variation of $\rho_{t}$ for large values, and small variation for small values, i.e. multiplicative, rather than additive, day-to-day changes. Thus, we assume that 
$$
    \log \rho_{t + 1} = \log \rho_{t} + \varepsilon_{t + 1, \rho}
$$
for $\varepsilon_{t + 1,\rho} \sim \mathcal N(0, \sigma^{2}_\rho)$. To incorporate weekday effects, consider a weekly seasonal component on the log-scale 
$$
    \log W_{t + 1} = - \sum_{s = 0}^{5} \log W_{t - s} + \varepsilon_{t + 1, W},
$$
for $\varepsilon_{t + 1, W} \sim \mathcal N(0, \sigma^{2}_{W})$. Finally, to model the reporting delay probabilities $p_{t,\tau}$, $\tau = 1,2,3,4$, we parameterize them by log ratios
\begin{align*}
    q_{t, \tau} = \log \frac{p_{t,\tau}}{p_{t,4}} && \tau = 1, 2, 3,
\end{align*}
which also perform a random walk in time: 
$$
    q_{t + 1, \tau} = q_{t, \tau} + \varepsilon_{t+1, q, \tau},
$$
with $\varepsilon_{t + 1, q, \tau} \sim \mathcal N(0, \sigma^{2}_{q})$ whose variance does not depend on the delay $\tau$. To account for the weekday effect visible in \Cref{fig:weekday_effect_delays}, we introduce three further weekday effects, for $\tau = 1,  2, 3$ let
$$
    \log W^{q,\tau}_{t + 1} = - \sum_{s = 0}^{5} \log W^{q,\tau}_{t - s} + \varepsilon_{t + 1, W^{q,\tau}},
$$
with $\varepsilon_{t+1, W^{q,\tau}} \sim \mathcal N \left( 0, \sigma^{2}_{W_q} \right)$ and shared variance $\sigma^{2}_{W_{q}}$.
We can recover the delay probabilities $p_{t, \tau}$ from the log-ratios by 
\begin{align}
    \begin{split}
        \label{eq:p-from-log-ratios}
    p_{t, 4} &= \frac{1}{1 + \sum_{\tau = 1}^3 \exp \left( q_{t,\tau} + \log W^{q,\tau}_{t} \right)}, \\
    p_{t, \tau} &= \exp\left( q_{t, \tau + \log W^{q, \tau}_{t}} \right) p_{t, 4},
    \end{split}
\end{align}
for $\tau = 1, 2, 3$.

Finally, there are reporting artifacts and other effects that we have not yet considered in our model that contribute to the variation in the data. To account for these effects, we model daily, multiplicative, ``{}muck''{} $M_{t}$, for date $t$, such that the total expected number of reported cases on this date is $M_{t}I_{t}$ instead of $I_{t}$. We assume that $(\log M_{t})_{t = 0, \dots, n} \iid \mathcal N(-\frac{1}{2}\sigma^{2}_M, \sigma^{2}_{M})$, independent of all other states. Thus, $M_{t}$ follows a log-normal distribution with mean $1$. 

With these components at our disposal, we can model the observed incidences $Y_{t, \tau}$ by
\begin{align}
    \label{eq:reporting_delays_Y}
    Y_{t, \tau} | \log I_{t}, \log W_{t}, q_{t}, \log M_{t} \sim \operatorname{Pois} \left( p_{t, \tau}\exp \left(\log I_{t} + \log W_{t}  + \log M_{t}\right) \right),
\end{align}
conditionally independent for fixed $t$. Thus, $W_{t}$ acts as a multiplicative factor that modulates the observed cases depending on the day of the week, and the delay probabilities distribute the total expected number of cases $M_{t}W_{t}I_{t}$ onto the delays. In this model, $Y_{t} = \sum_{\tau = 1}^4 Y_{t, \tau}$ has conditional expectation 
$$
    \E \left( Y_{t} | \log I_{t}, \log W_{t}, q_{t}, \log M_{t} \right) = M_{t}W_{t}I_t.
$$
As it is sensible to model the conditional distribution of $Y_{t}$ by a Poisson distribution (see \Cref{sec:dessiderata}), we can view \Cref{eq:reporting_delays_Y} as a multinomial thinning of this distribution. Notice that including $M_{t}$ introduces overdispersion in this Poisson distribution, similar to modeling with a negative binomial distribution. 

Letting $$X_{t} =\left( \log I_{t}, \log \rho_{t + 1}, \log W_{t}, \dots, \log W_{t - 5}, q_{t,1}, q_{t,2}, q_{t,3}, \log W^{q,1}_{t}, \dots, \log W^{q,3}_{t - 5}\right)^{T},$$ assuming that
$$
\varepsilon_{t + 1} = 
\begin{pmatrix}
     \varepsilon_{t + 1,\rho}\\ \varepsilon_{t + 1, W}\\ \varepsilon_{t +1, q, 1}\\ \varepsilon_{t +1, q, 2}\\ \varepsilon_{t +1, q, 3}
\end{pmatrix}
$$
has independent marginals, and fixing an initial distribution of $X_{0}$ fully specifies a \acrshort{pgssm} for the joint distribution of $(X,Y)$. For the initial distribution we use 
$$
    X_{0} \sim \mathcal N \left( u_{0}, \Sigma_{0} \right)
$$
where $u_{0}$ is $0$ for all elements, except to the third entry (corresponding to $M_{0}$), which we set to $-\frac{1}{2} \sigma^{2}_M$. For the initial covariance we use a diagonal matrix, which is based on numerical experiments (for $\log I$ and $\log \rho$) and the fact that a log-normal with parameter $\sigma^{2} = 1$ (the variance of the involved normal distribution) roughly models being off by one order of magnitude\footnote{The $1\%$-quantile is $\approx 0.1$ and the $99\%$-quantile is $\approx 10$.}. We let
$$
    \Sigma_{0} = \diag \left( 
        \underbrace{5^{2}}_{\log I},
        \underbrace{0.2^{2}}_{\log \rho},
        \underbrace{s^{2}_M}_{M},
        \underbrace{1}_{\log W_{0}},
        \dots,
        \underbrace{1}_{\log W_{-5}},
        \underbrace{1}_{q_{0, 1}},
        \underbrace{1}_{q_{0, 2}},
        \underbrace{1}_{q_{0, 3}},
        \underbrace{1}_{\log W^{q,1}_{0}},
        \dots,
        \underbrace{1}_{\log W^{q,3}_{-5}}
    \right).
$$

The model has a linear signal 
$$
    S_{t} = \begin{pmatrix}
        \log I_{t} + \log W_{t} \\
        q_{t, 1} \\
        q_{t, 2} \\
        q_{t, 3} 
    \end{pmatrix},
$$
but due to the non-linear dependence of $p_{t,\tau}$ on $q_{t,\tau}$,  $Y_{t,\tau}$ depends not just on $S_{t, \tau}$ but on the whole of $S_{t}$. Fortunately, this is not a problem for either the \acrshort{la} or \acrshort{eis}. For the \acrshort{la} (\Cref{alg:la}), notice that the covariance matrix $\Omega_{t}$ is given by the inverse of the negative Hessian of $s_{t} \mapsto \log p(y_{t}|s_{t})$, which is now non-diagonal. While it is not guaranteed that $\Omega_{t}$ is positive semi-definite during the Newton-Raphson iteration, we can still employ the Kalman filter and signal smoother to perform the iteration efficiently, see \citep{Jungbacker2007Monte} and the discussion in \Cref{subsec:glssm-approach}. Furthermore, at the global optimum, the Hessian is negative semi-definite, so $\Omega_{t}$ is positive semi-definite, specifying a valid \acrshort{glssm} proposal. 
Similarly, we may extend \acrshort{eis} to account for non-diagonal $\Omega_{t}$. Recall from \Cref{subsec:eis}, that \acrshort{eis} minimizes for a given $t$ 
$$
    \sum_{i = 1}^N \left( \log p(y_{t} | S^{i}_t) + \langle \Omega_{t}^{-1}z_{t}, S^{i}_{t}\rangle - \frac{1}{2} \operatorname{tr} \left(\Omega^{-1}_{t}S^{i}_{t}(S^{i}_t)^{T}\right)- \lambda_{t} \right)^{2}
$$
over $z_{t}, \Omega_{t}, \lambda_{t}$. Noticing that $(A,B) \mapsto \operatorname{tr} \left( A^{T}B \right)$ is the Frobenius inner-product, we see that this optimization problem is still a weighted linear least squares problem for $\Omega_{t}^{-1}z_{t}, \Omega^{-1}_t, \lambda_{t}$, when we let $\Omega_{t}^{-1}$ take values in the symmetric matrices in $\R^{p \times p}$. As the dimension of this vector space is $ \frac{p (p + 1)}{2}$, we may still perform the computationally efficient weighted linear least squares routine, but at an increased cost: the number of parameters increases from $2p + 1$ ($\Omega_{t}$ diagonal) to $p + \frac{p(p + 1)}{2} + 1$ ($\Omega_{t}$ symmetric). 

The parameters of the model are $\theta = \left( \log \sigma^{2}_{\rho}, \log \sigma^{2}_{W}, \log \sigma^{2}_{q}, \log \sigma^{2}_M, \log \sigma^{2}_{W_{q}}\right)$, which we model on the log-scale to avoid having to take care of constraints. Given observations $Y = (Y_{0}, \dots, Y_{n})$ we perform maximum likelihood estimation as described in \Cref{alg:mle}. As tuning parameters in this procedure we use $20$ iterations for the \acrshort{la} and \acrshort{eis}, with relative tolerance of convergence set to $10^{-5}$. For the \acrshort{eis} proposals we also use $1\,000$ samples and all four antithetic variables, i.e. we use \Cref{eq:antithetic-weights}. At the \acrshort{mle} we again determine the \acrshort{eis} proposal using the same parameters and perform inference for the conditional distribution using $10\,000$ samples, applying the method described in \Cref{subsec:inference} to obtain estimates of the posterior mean, standard deviation and prediction intervals. 

% results
\subsection{Results}
\paragraph{Showcase}
We start by a showcase of the models' capability, fitting it to the reported case date in the period from April 5th to September 1st 2020, starting from the first day when $4$ delays are available in the dataset to the initial period of exponential growth in the fall of 2020. We estimate the parameters $\theta = \left( \log \sigma^{2}_{\rho}, \log \sigma^{2}_W, \log \sigma^{2}_q, \log \sigma^{2}_M, \log \sigma^{2}_{W_{q}}\right)$ by maximum-likelihood estimation, yielding the parameters displayed in \Cref{tab:showcase-parameters}. There, we see that $\log \rho_{t}$, $\log W_{t}$, $q_{t,1}, q_{t,2}$ and $ q_{t,3}$ vary slowly over time, compared to the faster varying $W^{q, 1}, W^{q,2}, W^{q,3}$. 

\begin{table}
    \centering
    \input{tables/showcase-parameters.tex}
    \caption{Standard deviations for the models' showcase determined either by hand, by the initial search or by maximum likelihood estimation described in \Cref{sec:maximum_likelihood_estimation}. The difference between the initial search and the \acrshort{mle} is negligible and is not visible for the precision shown here.}
    \label{tab:showcase-parameters}
\end{table}
\begin{figure}
    \resizebox{\textwidth}{!}{%
        \input{tikz/showcase_prediction_intervals_I_rho.tex}%
    }
    \caption{Monte-Carlo estimates of mean (black lines) and $95\%$ prediction intervals (shaded green regions) for smoothed incidences $I$ and daily growth factors $\rho$. The total reported cases with delay at most $4$ days,  $Y_{t}$, is shown as a dotted line. The secondary axis for the daily growth factor $\rho$ indicates the corresponding weekly growth factors $\rho^{7}$ which are easier to interpret. The gray dashed line indicates the threshold for growth $\rho = 1$.}
    \label{fig:showcase_prediction_intervals_I_rho}
\end{figure}

We show importance sampling estimates of the mean and $95\%$ prediction intervals of the conditional distribution of $I$ and $\rho$ (\Cref{fig:showcase_prediction_intervals_I_rho}) as well as $W,M$ and $p$ (\Cref{fig:showcase_prediction_intervals}), based on the procedure described in \Cref{subsec:inference}. For $I$ we additionally show the total number of reported cases with delay at most $4$ days, $Y_{t,\cdot} = Y_{t, 1} + \dots + Y_{t, 4}$, as a sanity check. Indeed, $I$ is a smoothed version of $Y$, which removes weekday-effects and small discrepancies in reporting, as these effects are captured by the $W$ and $M$ terms.

For the daily growth factor $\rho$ we additionally display the corresponding weekly growth factors $\rho^{7}$ on the secondary axis. We see that uncertainty for $\rho$ is roughly constant over time, except close to the beginning and end of the time period considered here. We see that until June 2020 $\rho$ is below $1$, followed by a short skip above $1$ during the local outbreak highlighted in \Cref{fig:cases_germany} and a return to $\rho < 1$ until beginning of July 2020. We will deal with this sudden increase and the following decrease more extensively in the following section. From the middle of July 2020 to the middle of August 2020, $\rho$ is consistently above $1$, with a slight dip at the end of August, before rising above $1$ again. That cases are, or will be, rising exponentially is easier to infer from $\rho$ compared to $I$, as $\rho$, or $\rho^7$ for that matter, directly quantifies the increase in cases. Thus, this sustained period of exponential growth could have been a warning sign to policymakers of the buildup of infections in the population, which only became noticeable in the cases starting in October 2020. 

\begin{figure}
    \resizebox{\textwidth}{!}{%
        \input{tikz/showcase_prediction_intervals.tex}%
    }
    \caption{Importance sampling estimates of mean (black lines) and $95\%$ prediction intervals (green ribbons) for weekday effect, ``{}muck''{} and delay probabilities in the showcase model, based on the method described in \Cref{subsec:inference}. We omit the small prediction intervals for delay probabilities for better readability. Note that all variables are not included directly in the model, but may be written as a function of states, either taking the exponential or converting from log-ratios to probabilities. The minor breaks in the x-axis grid indicate Sundays.} \label{fig:showcase_prediction_intervals}
\end{figure}
% muck

For the muck term $M$, we see that is centered around $1$ and allows capturing variation of the reported cases that is not captured by other terms in the model. As $M$ follows a log Normal distribution, its variance is $\left( \exp \left( \sigma^{2}_M \right) - 1 \right) \exp \left( 2 (- \frac{1}{2} \sigma^{2}_M) +\sigma^{2}_M \right) = \exp \left( \sigma^{2}_M - 1\right)$, so $M$ has standard deviation $\approx 0.12$ for the MLE from \Cref{tab:showcase-parameters}, consistent with \Cref{fig:showcase_prediction_intervals}. As such, we expect the reported cases to vary around $\pm 24\%$ on any given day, due to residual effects not captured by the weekday effect. We also investigated qq-plots of the mean predictions of $M$, which indicate that there might be some outliers, e.g. those around the local outbreak in June 2020, present. To improve the fit, we could replace the distribution of $M$ by, e.g., a t-distribution with a low degree of freedom, allowing for heavier tails. The \acrshort{la} for such a model can still be found efficiently, see \citep[Section 11.7.2]{Durbin2012Time}, so the methods of this section are still applicable. However, we deem such a modification to be outside the scope of this thesis. 

% weekday effect
The weekday effect $W$ exhibits the expected seasonal pattern: on Sundays, which are marked by the minor breaks in the figures' grid, $W$ is below $1$, while it is high for Tuesdays, Wednesdays and Thursdays. Over the period considered, this pattern is quite stable, with only slight changes over time: $W$ is slightly larger for Mondays and Fridays at the end of the period compared to the beginning. By construction, we have $\overline{\log W_{t}} = \frac{1}{7}\sum_{\tau = -3}^3 \log W_{t - \tau} \approx 0$ for all $t$, so Jensen's inequality suggests $\frac{1}{7} \sum_{\tau = -3}^3 W_{t - \tau} \gtrapprox 1$. However, the practical difference is small: $$ \frac{1}{7} \sum_{\tau = -3}^3 \E (W_{t - \tau} | Y) \approx 1.05,$$ for $t = 3, \dots, n-3$, with small standard deviation. Consequently, we could correct $I_{t}$ for the bias introduced by $W$ by an increase of $5\%$ (or, more precisely, consider $ I_{t} \bar W_{t} $). 

% delay probabilities
Finally, for the delay probabilities, we compute both the signals probabilities, given by \Cref{eq:p-from-log-ratios}, and a smoothed version, obtained by setting $\log W_{t}^{q,\tau}$ to $0$ in \Cref{eq:p-from-log-ratios}. From \Cref{fig:showcase_prediction_intervals}, we see that starting in the middle of April, reporting became faster, with a larger share of cases being reported with a delay of only a single day. While this seems to reverse at the end of the considered period, this is likely due to the reporting artifacts at the end of August, indicated by the large spike in $p_{t,2}$. 

\paragraph{reporting artifacts in Christmas season 2020}
Now that we have seen an application of the model, we use it to demonstrate how easily we can incorporate missing or faulty observations. Recall from \Cref{fig:cases_germany} the problem of reporting artifacts during the 2020 Christmas season. In \Cref{fig:christmas_prediction_intervals_I_rho} we show undesirable effects of directly applying our model to the data in this period. In this figure, the red lines correspond to inferences made using all available observations, while turquoise lines correspond to inferences made where we remove all observations from December 19th 2020 until January 17th 2021, marked by the gray background in the figure. 
\begin{figure}
    \resizebox{\textwidth}{!}{%
        \input{tikz/christmas_prediction_intervals_I_rho.tex}%
    }
    \caption{Importance sampling estimates of $95\%$ prediction intervals and means of the conditional distribution of $I$ and $\rho$ given reported cases for the reporting delay model applied to the period of October 1st 2020 until February 28th 2021. For $I$ we additionally show weekly average reported cases as in \Cref{fig:cases_germany}. }
    \label{fig:christmas_prediction_intervals_I_rho}
\end{figure}

We can fit both models using the same methods, as we only have to replace the observation matrices $B_{t}$ for missing dates $t$ by zero matrices and the conditional distribution of $Y_{t, \tau} | S_{t}$ by $\delta_{0}$, while replacing $Y_{t,\tau}$ by $0$ for $\tau = 1, \dots, 4$. In the approximating \acrshortpl{la} and \acrshort{eis} proposals we set $z_{t}$ and $\Omega_{t}$ to the zero vector and matrix, respectively. 

For the model using all available data, we see that the reporting artifacts affect both the incidences $I$ and growth factors $\rho$, with a sharp decrease in $\rho$ during the holidays, followed by a sharp increase in the new year. For the model that has the flawed observations removed, we see that both $I$ and $\rho$ behave more smoothly, as the estimated standard deviations, displayed in \Cref{tab:christmas-parameters}, are also smaller. The price we pay for this smoother transition is larger uncertainty where observations are now missing, i.e. the $95\%$ prediction intervals are larger in this period than those for the model with all data available. However, when data are available, the prediction intervals for the second model are smaller, as its estimated standard deviations are smaller. The means, however, tend to agree rather well. 

\begin{table}
    \centering
    \input{tables/christmas-parameters.tex}
    \caption{Estimated parameters for the model during the Christmas period, for all observations or with observations during the Christmas period (19th December 2020 until January 17th 2021) removed. The manual parameter is based on the estimate of the models' showcase, i.e. the \acrshort{mle} result from \Cref{tab:showcase-parameters}.}
    \label{tab:christmas-parameters}
\end{table}

In \Cref{fig:christmas_delay_probs} we additionally show the expected smoothed delay probabilities based on \Cref{eq:p-from-log-ratios} where we set the weekday effects to $0$. There, we see that starting on December 24th, the reporting pattern exhibits strong irregular behavior (recall that the reported cases for December 24th correspond to December 23rd to December 20th for delays $\tau =1, \dots, 4$) for the model using all observations. Additionally, in January, we a large spike in $p_{t,1}$, which could correspond to a backlog of cases being reported all at once. Again, the model that has the Christmas period removed, proceeds much smoother.

\begin{figure}
    \resizebox{\textwidth}{!}{%
        \input{tikz/christmas_delay_probs.tex}%
    }
    \caption{Importance sampling estimates of conditional expectation $\E \left( p_{t, \tau} | Y \right)$ for the two sets of Christmas observations: the full lines correspond to all reported incidences and the dashed lines to observations between December 19th 2020 and January 17th 2021 removed. When using all observations, we clearly see the effect of the Christmas holidays, with a drop in next day reporting during the holidays, and an increase in next day reporting in the middle of January.}
    \label{fig:christmas_delay_probs}
\end{figure}

\subsection{Discussion}
% highlight that this is a good model
%% allows to account for time evolution of cases, while taking care of artifacts etc.
%% estimated growth factors + uncertainty allow to infer about current state of epidemic
As we can see from the exemplary results, the model allows to accurately model the evolution of reported cases over time, while taking care of unwelcome reporting artifacts such as the weekday effect, delays and changes in reporting pattern due to holidays. 
The estimated growth factors allow inferring about the speed at which the cases proliferate, and can thus be a valuable tool for decision makers. With our model, we can identify the almost constant exponential growth in the summer of 2020 (\Cref{fig:showcase_prediction_intervals_I_rho}), which is difficult to see by only looking at the number of reported cases, due to the reporting artifacts and low number of cases. 

As our model explicitly models reporting delays, we can infer about them as well. From \Cref{fig:showcase_prediction_intervals,fig:christmas_delay_probs} we can see that during the first year of the epidemic, reporting became faster: while only about 40\% of cases were reported with delay of one day in April 2020, that fraction rose to more than 60\% at the end of 2020, excluding the noisy Christmas period. By including reporting delays, our model is also capable of performing now- and forecasts of future reported cases. For forecasts, we evaluate the performance of seven day predictions from this model in the following section.

% advantages over models that only do prediction
%% interpretability, diagnostics, missingness easily incorporated,  
The \acrshort{ssm} nature of our model has the additional advantage of being capable of naturally handling missing observations, either actual missing observations or synthetically missing observations, such as in the Christmas period. By removing available observations from the model, we are able to create a what-if scenario, letting the model automatically fill-in the faulty observations. Let us hasten to add that this should not be confused with redistributing the number of cases observed in the Christmas period to better fit the model, as we have not included any restrictions on the total number of cases being equal to the observed number of cases in this period. Technically, this is possible, by adding $\log I_{t - 1}, \dots, \log I_{t - D + 1}$, where $D$ is the number of days removed, to the states and adding a single observation of $\sum_{s = 0}^{D - 1} I_{t^{\ast} - s}$ at time $t^{\ast}$, the first day after the Christmas period is over. Removing the observations from December 19th 2020 to January 17th 2021 removes a total of $551\,031$ cases. In the Christmas model, the predictive distribution of cases for this time period has mean $618\,000$ (standard deviation $59,000$) with a $95\%$ prediction interval of $(511\,000, 743\,000)$ (all numbers rounded to the next thousand due to Monte Carlo error). Thus, our reconstruction of the total number of cases is compatible with the total number of cases removed, albeit slightly overestimating the total number of cases.

While we believe that our model already captures many of the relevant effects for modeling the daily evolution of cases, there are several worthwhile extensions conceivable. We here give an incomplete list of potential improvements:
\begin{itemize}
    \item We have only used the reporting date in our model, but the data include also information (for some cases) on the symptom onset date. Including this would also allow to better remove the weekday effect, as infection dates, presumably, are less affected by weekdays than reported cases.
    \item In the same vein, including data on deaths would allow for estimates of the reporting dark figure, and its change over time, as long as immunization through infection and vaccination is low, i.e. at the beginning of the epidemic.
    %\item Instead of using hand-picked priors for the initial distribution, we could extend our models to use the diffuse initialization method of \citep[Chapter 5 \& 11]{Durbin2012Time}, to be less reliant on hand-picked initial values. 
\end{itemize}

Most of these improvements require the use of additional data sources, which is straightforward to do with state space models: we just have to extend the states and dynamics accordingly. 
# AUTOGENERATED! DO NOT EDIT! File to edit: ../10_model.ipynb.

# %% auto 0
__all__ = ['key', 'n_iterations', 'N_mle', 'N_meis', 'N_posterior', 'par_manual', 'theta_manual', 'np1', 'aux', 'y',
           'growth_factor_model', 'par_to_theta', 'theta_to_par']

# %% ../10_model.ipynb 2
import jax.numpy as jnp
import jax.scipy as jsp
import jax
from jax import vmap, jit
import matplotlib.pyplot as plt
import matplotlib as mpl
import pandas as pd
import jax.random as jrn

from isssm.typing import PGSSM, GLSSMState
from jaxtyping import Array, Float

from tensorflow_probability.substrates.jax.distributions import (
    NegativeBinomial as NBinom,
)

# %% ../10_model.ipynb 3
key = jrn.PRNGKey(452342342345)
n_iterations = 20
N_mle = 1000
N_meis = 1000
N_posterior = 10000

# %% ../10_model.ipynb 6
def _state_model(r0, u0, alpha, s2_rho, Omega, n) -> GLSSMState:
    (K,) = u0.shape
    A = jnp.broadcast_to(jsp.linalg.block_diag(alpha, jnp.eye(K)), (n, K + 1, K + 1))
    Sigma0 = jsp.linalg.block_diag(s2_rho, 1 / (1 - alpha**2) * Omega)
    Sigma = jsp.linalg.block_diag(s2_rho * jnp.eye(1), 1 / (1 - alpha**2) * Omega)
    Sigma = jnp.broadcast_to(Sigma, (n, K + 1, K + 1))

    x0 = jnp.concatenate([r0, u0])
    D = jnp.broadcast_to(jnp.eye(K + 1), (n, K + 1, K + 1))
    u = jnp.zeros((n + 1, K + 1))
    u = u.at[0].set(x0)

    return GLSSMState(u, A, D, Sigma0, Sigma)

# %% ../10_model.ipynb 8
def _observation_model(obs: Float[Array, "n+2 K"], P: Float[Array, "K K"], r: Float):

    np2, p = obs.shape
    np1 = np2 - 1

    delayed_obs = obs[:-1]
    cases_adjusted = vmap(jnp.matmul, (None, 0))(P, delayed_obs)

    xi = jnp.concatenate(
        (jnp.full((np1, p, 1), r), cases_adjusted[:, :, None]), axis=-1
    )

    def dist_obs(signal, xi):
        r, sum_I = jnp.moveaxis(xi, -1, 0)
        return NBinom(r, logits=signal + jnp.log(sum_I) - jnp.log(r))

    B = jnp.hstack([jnp.ones((p, 1)), jnp.eye(p)])
    B = jnp.broadcast_to(B, (np1, p, p + 1))
    v = jnp.zeros((np1, p))

    return v, B, dist_obs, xi

# %% ../10_model.ipynb 11
def _P(C, q, n_ij, n_tot) -> Float[Array, "K K"]:
    p, _ = n_ij.shape
    m_ij = n_ij + jnp.diag(C * n_tot - n_ij.sum(axis=1))
    normalize_rows = lambda x: x / x.sum(axis=1).reshape((-1, 1))
    return jnp.full((p, p), q / p) + (1 - q) * normalize_rows(m_ij)

# %% ../10_model.ipynb 14
def growth_factor_model(theta, aux) -> PGSSM:

    logit_alpha, log_s2_r, log_s2_spat, logit_q, log_Cm1, log_r = theta
    obs, n_ij, n_tot = aux
    C = jnp.exp(log_Cm1) + 1

    np2, _ = obs.shape
    np1 = np2 - 1
    (K,) = n_tot.shape

    m = K + 1
    p = K
    l = K + 1

    alpha = jsp.special.expit(logit_alpha)
    s2_rho = jnp.exp(log_s2_r)
    s2_spat = jnp.exp(log_s2_spat)
    r = jnp.exp(log_r)
    q = jsp.special.expit(logit_q)

    P = _P(C, q, n_ij, n_tot)
    state = _state_model(
        jnp.zeros(1), jnp.zeros(K), alpha, s2_rho, s2_spat * P @ P.T, np1 - 1
    )
    obs = _observation_model(obs, P, r)

    return PGSSM(*state, *obs)

# %% ../10_model.ipynb 19
import jax.scipy as jsp

# obs, n_ij, n_tot = aux


def par_to_theta(params):
    alpha, s2_r, s2_spat, q, C, r = params
    return jnp.array(
        [
            jsp.special.logit(alpha),
            jnp.log(s2_r),
            jnp.log(s2_spat),
            jsp.special.logit(q),
            jnp.log(C - 1),
            jnp.log(r),
        ]
    )


def theta_to_par(theta):
    alpha, s2_r, s2_spat, q, Cm1, r = theta
    return jnp.array(
        [
            jsp.special.expit(alpha),
            jnp.exp(s2_r),
            jnp.exp(s2_spat),
            jsp.special.expit(q),
            jnp.exp(Cm1) + 1,
            jnp.exp(r),
        ]
    )


par_manual = jnp.array([0.5, 0.01**2, 0.01**2, 0.5, 2, 100.0])
theta_manual = par_to_theta(par_manual)
np1 = 10
aux = (cases_full[: np1 + 1], n_ij, n_tot)
y = cases_full[1 : np1 + 1]

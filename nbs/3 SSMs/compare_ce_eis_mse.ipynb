{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "---\n",
    "skip_exec: true    # Skips in tests\n",
    "skip_showdoc: true # Skips in docs builds\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.9 Comparison of importance sampling methods\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simulation study CE vs. EIS bias/variance/rho"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax\n",
    "from jax import vmap\n",
    "import jax.numpy as jnp\n",
    "import jax.random as jrn\n",
    "from functools import partial\n",
    "from jaxtyping import Array, Float\n",
    "from pyprojroot.here import here\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "from isssm.laplace_approximation import laplace_approximation as mode_estimation\n",
    "from isssm.modified_efficient_importance_sampling import (\n",
    "    modified_efficient_importance_sampling,\n",
    ")\n",
    "from ssm4epi.ce_method import (\n",
    "    ce_cholesky_precision,\n",
    "    marginals,\n",
    "    simulate as simulate_ce,\n",
    "    ce_log_weights,\n",
    "    forward_model_markov_process,\n",
    ")\n",
    "from isssm.importance_sampling import ess_pct\n",
    "from isssm.importance_sampling import (\n",
    "    pgssm_importance_sampling as lcssm_importance_sampling,\n",
    ")\n",
    "from isssm.models.pgssm import nb_pgssm as nb_lcssm\n",
    "from isssm.kalman import kalman, smoother\n",
    "from tensorflow_probability.substrates.jax.distributions import WishartTriL as Wishart\n",
    "from isssm.kalman import kalman\n",
    "from isssm.importance_sampling import log_weights_t\n",
    "from tensorflow_probability.substrates.jax.distributions import (\n",
    "    MultivariateNormalFullCovariance as MVN,\n",
    ")\n",
    "from ipywidgets import IntProgress\n",
    "from IPython.display import display\n",
    "\n",
    "key = jrn.PRNGKey(342234)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Efficient calculation of weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_weights_ssm(y, x0, A, B, Sigma, z, Omega, dist, xi, N, key):\n",
    "    \"\"\"Calculate the efficiency factor while sampling only the marginal distributions, keeping memory impact minimal\"\"\"\n",
    "    x_filt, Xi_filt, x_pred, Xi_pred = kalman(z, x0, Sigma, Omega, A, B)\n",
    "\n",
    "    def _sample_and_weights(carry, inputs):\n",
    "        X_smooth_next, log_w, key = carry\n",
    "        x_filt, Xi_filt, Xi_pred, A_t, B_t, y_t, xi_t, z_t, Omega_t = inputs\n",
    "\n",
    "        G = Xi_filt @ jnp.linalg.solve(Xi_pred, A_t).T\n",
    "\n",
    "        cond_expectation = x_filt + vmatmul(G, X_smooth_next - (A_t @ x_filt)[None])\n",
    "        cond_covariance = Xi_filt - G @ Xi_pred @ G.T\n",
    "\n",
    "        key, subkey = jrn.split(key)\n",
    "        new_samples = MVN(cond_expectation, cond_covariance).sample(seed=subkey)\n",
    "\n",
    "        s_t = vmap(jnp.matmul, (None, 0))(B_t, new_samples)\n",
    "        log_w = log_w + vmap(\n",
    "            partial(\n",
    "                log_weights_t, y_t=y_t, xi_t=xi_t, dist=dist, z_t=z_t, Omega_t=Omega_t\n",
    "            )\n",
    "        )(s_t)\n",
    "\n",
    "        return (new_samples, log_w, key), jnp.empty((0,))\n",
    "\n",
    "    key, subkey = jrn.split(key)\n",
    "\n",
    "    initial_samples = MVN(x_filt[-1], Xi_filt[-1]).sample(N, seed=subkey)\n",
    "    initial_signals = vmap(jnp.matmul, (None, 0))(B[-1], initial_samples)\n",
    "    initial_log_weights = vmap(\n",
    "        partial(\n",
    "            log_weights_t,\n",
    "            y_t=y[-1],\n",
    "            xi_t=xi[-1],\n",
    "            dist=dist,\n",
    "            z_t=z[-1],\n",
    "            Omega_t=Omega[-1],\n",
    "        )\n",
    "    )(initial_signals)\n",
    "\n",
    "    (_, log_weights, _), _ = jax.lax.scan(\n",
    "        _sample_and_weights,\n",
    "        (initial_samples, initial_log_weights, subkey),\n",
    "        (\n",
    "            x_filt[:-1],\n",
    "            Xi_filt[:-1],\n",
    "            Xi_pred[1:],\n",
    "            A,\n",
    "            B[:-1],\n",
    "            y[:-1],\n",
    "            xi[:-1],\n",
    "            z[:-1],\n",
    "            Omega[:-1],\n",
    "        ),\n",
    "        reverse=True,\n",
    "    )\n",
    "\n",
    "    return log_weights\n",
    "\n",
    "\n",
    "# ess_pct(log_weights_ssm(Y, x0, A_t, B, Sigma, z_la, Omega_la, dist, xi, N_true, subkey)), results_la.mean()[\"ef\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## simulation code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eis_marginals(x0, A, Sigma, B, z, Omega):\n",
    "    x_filt, Xi_filt, x_pred, Xi_pred = kalman(z, x0, Sigma, Omega, A, B)\n",
    "    x_smooth, Xi_smooth = smoother(x_filt, Xi_filt, x_pred, Xi_pred, A)\n",
    "\n",
    "    marg_means = x_smooth\n",
    "    marg_vars = vmap(jnp.diag)(Xi_smooth)\n",
    "\n",
    "    return marg_means, marg_vars\n",
    "\n",
    "\n",
    "def eis_single_outcome(key, N, Y, x0, A, Sigma, B, dist, xi, z_la, Omega_la):\n",
    "    key, subkey = jrn.split(key)\n",
    "    z_eis, Omega_eis = modified_efficient_importance_sampling(\n",
    "        Y, x0, A, Sigma, B, xi, dist, z_la, Omega_la, 1, N, subkey\n",
    "    )\n",
    "\n",
    "    key, subkey = jrn.split(key)\n",
    "    _, log_weights = lcssm_importance_sampling(\n",
    "        Y, x0, A, Sigma, B, dist, xi, z_eis, Omega_eis, N, subkey\n",
    "    )\n",
    "\n",
    "    return *(eis_marginals(x0, A, Sigma, B, z_eis, Omega_eis)), ess_pct(log_weights)\n",
    "\n",
    "\n",
    "def ce_single_outcome(key, N, Y, x0, A, Sigma, B, dist, xi, z_la, Omega_la):\n",
    "    key, subkey = jrn.split(key)\n",
    "\n",
    "    samples, log_weights = lcssm_importance_sampling(\n",
    "        Y, x0, A, Sigma, B, dist, xi, z_la, Omega_la, N, subkey\n",
    "    )\n",
    "\n",
    "    initial_mean, (initial_diag, initial_off_diag) = forward_model_markov_process(\n",
    "        z_la, x0, A, B, Sigma, Omega_la\n",
    "    )\n",
    "\n",
    "    (diag, off_diag, mean), _, _ = ce_cholesky_precision(\n",
    "        Y,\n",
    "        x0,\n",
    "        A,\n",
    "        Sigma,\n",
    "        B,\n",
    "        xi,\n",
    "        dist,\n",
    "        initial_mean,\n",
    "        initial_diag,\n",
    "        initial_off_diag,\n",
    "        1,\n",
    "        N,\n",
    "        subkey,\n",
    "    )\n",
    "\n",
    "    key, subkey = jrn.split(key)\n",
    "    samples = simulate_ce(diag, off_diag, subkey, N)\n",
    "\n",
    "    log_weights = vmap(\n",
    "        partial(\n",
    "            ce_log_weights,\n",
    "            y=Y,\n",
    "            full_diag=diag,\n",
    "            off_diag=off_diag,\n",
    "            mean=mean,\n",
    "            x0=x0,\n",
    "            A=A,\n",
    "            Sigma=Sigma,\n",
    "            B=B,\n",
    "            dist=dist,\n",
    "            xi=xi,\n",
    "        )\n",
    "    )(samples)\n",
    "\n",
    "    return *(marginals(mean, diag, off_diag)), ess_pct(log_weights)\n",
    "\n",
    "\n",
    "def bias_var(samples: Float[Array, \"M ...\"], true: Float[Array, \"...\"]):\n",
    "    bias_sr = (samples - true) ** 2\n",
    "    var = (samples - samples.mean(axis=0)) ** 2\n",
    "    return bias_sr, var\n",
    "\n",
    "\n",
    "def eis_outcomes(\n",
    "    N, key, M, true_z, true_Omega, Y, x0, A, Sigma, B, dist, xi, z_la, Omega_la\n",
    "):\n",
    "    key, *subkeys = jrn.split(key, M + 1)\n",
    "    subkeys = jnp.array(subkeys)\n",
    "\n",
    "    true_mean, true_var = eis_marginals(x0, A, Sigma, B, true_z, true_Omega)\n",
    "\n",
    "    single_run = partial(\n",
    "        eis_single_outcome,\n",
    "        Y=Y,\n",
    "        N=N,\n",
    "        x0=x0,\n",
    "        A=A,\n",
    "        Sigma=Sigma,\n",
    "        B=B,\n",
    "        dist=dist,\n",
    "        xi=xi,\n",
    "        z_la=z_la,\n",
    "        Omega_la=Omega_la,\n",
    "    )\n",
    "    marg_means, marg_vars, ef = vmap(single_run)(subkeys)\n",
    "\n",
    "    mean_bias, mean_var = bias_var(marg_means, true_mean)\n",
    "    var_bias, var_var = bias_var(marg_vars, true_var)\n",
    "\n",
    "    return pd.DataFrame(\n",
    "        {\n",
    "            \"N\": int(N),\n",
    "            \"N_mse\": M,\n",
    "            \"mean_bias\": mean_bias.mean(axis=(-2, -1)),\n",
    "            \"mean_var\": mean_var.mean(axis=(-2, -1)),\n",
    "            \"var_bias\": var_bias.mean(axis=(-2, -1)),\n",
    "            \"var_var\": var_var.mean(axis=(-2, -1)),\n",
    "            \"ef\": ef,\n",
    "        }\n",
    "    )\n",
    "\n",
    "\n",
    "def ce_outcomes(\n",
    "    N,\n",
    "    key,\n",
    "    M,\n",
    "    true_mean,\n",
    "    true_diag,\n",
    "    true_off_diag,\n",
    "    Y,\n",
    "    x0,\n",
    "    A,\n",
    "    Sigma,\n",
    "    B,\n",
    "    dist,\n",
    "    xi,\n",
    "    z_la,\n",
    "    Omega_la,\n",
    "):\n",
    "    key, *subkeys = jrn.split(key, M + 1)\n",
    "    subkeys = jnp.array(subkeys)\n",
    "\n",
    "    true_mean, true_var = marginals(true_mean, true_diag, true_off_diag)\n",
    "\n",
    "    single_run = partial(\n",
    "        ce_single_outcome,\n",
    "        N=N,\n",
    "        Y=Y,\n",
    "        x0=x0,\n",
    "        A=A,\n",
    "        Sigma=Sigma,\n",
    "        B=B,\n",
    "        dist=dist,\n",
    "        xi=xi,\n",
    "        z_la=z_la,\n",
    "        Omega_la=Omega_la,\n",
    "    )\n",
    "\n",
    "    marg_means, marg_vars, ef = vmap(single_run)(subkeys)\n",
    "\n",
    "    mean_bias, mean_var = bias_var(marg_means, true_mean)\n",
    "    var_bias, var_var = bias_var(marg_vars, true_var)\n",
    "\n",
    "    return pd.DataFrame(\n",
    "        {\n",
    "            \"N\": int(N),\n",
    "            \"N_mse\": M,\n",
    "            \"mean_bias\": mean_bias.mean(axis=(-2, -1)),\n",
    "            \"mean_var\": mean_var.mean(axis=(-2, -1)),\n",
    "            \"var_bias\": var_bias.mean(axis=(-2, -1)),\n",
    "            \"var_var\": var_var.mean(axis=(-2, -1)),\n",
    "            \"ef\": ef,\n",
    "        }\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from isssm.glssm import GLSSM\n",
    "x0 = jnp.zeros(1)\n",
    "n = 20\n",
    "alpha = 0.5\n",
    "A_t = alpha * jnp.tile(jnp.eye(1)[None, :, :], (n, 1, 1))\n",
    "Sigma = (1 - alpha**2) * jnp.tile(jnp.eye(1)[None, :, :], (n + 1, 1, 1))\n",
    "\n",
    "# NB observations\n",
    "glssm = GLSSM(\n",
    "    u=jnp.zeros((n, 1)),\n",
    "    A=A_t,\n",
    "    D\n",
    ")\n",
    "nb_model = nb_lcssm(\n",
    "    x0, A_t, Sigma, jnp.tile(jnp.eye(1)[None, :, :], (n + 1, 1, 1)), 0.1\n",
    ")\n",
    "x0, A_t, Sigma, B, dist, xi = nb_model\n",
    "\n",
    "key, subkey = jrn.split(key)\n",
    "(X,), (Y,) = simulate_lcssm(*nb_model, 1, subkey)\n",
    "\n",
    "s_init = vmap(jnp.dot)(B, X)\n",
    "X_smooth, z_la, Omega_la = mode_estimation(Y, x0, A_t, Sigma, B, dist, xi, s_init, 10)\n",
    "\n",
    "# more will result in OOMs\n",
    "N_true = int(1.5 * 1e6)\n",
    "M = 100\n",
    "Ns = jnp.logspace(1, 3.5, 10).astype(jnp.int32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LA simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "key, subkey_run = jrn.split(key)\n",
    "\n",
    "\n",
    "def la_single_outcome(key, N, Y, x0, A, Sigma, B, dist, xi, z, Omega):\n",
    "    _, log_weights = lcssm_importance_sampling(\n",
    "        Y, x0, A, Sigma, B, dist, xi, z, Omega, N, key\n",
    "    )\n",
    "    return ess_pct(log_weights)\n",
    "\n",
    "\n",
    "def la_outcomes(N, key, M, Y, x0, A, Sigma, B, dist, xi, z_la, Omega_la):\n",
    "    key, *subkeys = jrn.split(key, M + 1)\n",
    "    subkeys = jnp.array(subkeys)\n",
    "\n",
    "    single_run = partial(\n",
    "        la_single_outcome,\n",
    "        N=N,\n",
    "        Y=Y,\n",
    "        x0=x0,\n",
    "        A=A,\n",
    "        Sigma=Sigma,\n",
    "        B=B,\n",
    "        dist=dist,\n",
    "        xi=xi,\n",
    "        z=z_la,\n",
    "        Omega=Omega_la,\n",
    "    )\n",
    "\n",
    "    ef = vmap(single_run)(subkeys)\n",
    "\n",
    "    return pd.DataFrame(\n",
    "        {\n",
    "            \"N\": int(N),\n",
    "            \"N_mse\": M,\n",
    "            \"mean_bias\": None,\n",
    "            \"mean_var\": None,\n",
    "            \"var_bias\": None,\n",
    "            \"var_var\": None,\n",
    "            \"ef\": ef,\n",
    "        }\n",
    "    )\n",
    "\n",
    "\n",
    "results_la = pd.concat(\n",
    "    [\n",
    "        la_outcomes(N, subkey_run, M, Y, x0, A_t, Sigma, B, dist, xi, z_la, Omega_la)\n",
    "        for N in Ns\n",
    "    ]\n",
    ").reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EIS simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "key, subkey = jrn.split(key)\n",
    "true_z_eis, true_omega_eis = modified_efficient_importance_sampling(\n",
    "    Y,\n",
    "    x0,\n",
    "    A_t,\n",
    "    Sigma,\n",
    "    B,\n",
    "    xi,\n",
    "    dist,\n",
    "    z_la,\n",
    "    Omega_la,\n",
    "    1,\n",
    "    N_true,\n",
    "    subkey,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "single_N_run_eis = partial(\n",
    "    eis_outcomes,\n",
    "    Y=Y,\n",
    "    key=subkey_run,\n",
    "    M=M,\n",
    "    true_z=true_z_eis,\n",
    "    true_Omega=true_omega_eis,\n",
    "    x0=x0,\n",
    "    A=A_t,\n",
    "    Sigma=Sigma,\n",
    "    B=B,\n",
    "    dist=dist,\n",
    "    xi=xi,\n",
    "    z_la=z_la,\n",
    "    Omega_la=Omega_la,\n",
    ")\n",
    "\n",
    "results_eis = pd.concat([single_N_run_eis(N) for N in Ns]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CE simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "key, subkey = jrn.split(key)\n",
    "samples_la, log_weights_la = lcssm_importance_sampling(\n",
    "    Y, x0, A_t, Sigma, B, dist, xi, z_la, Omega_la, N_true, subkey\n",
    ")\n",
    "\n",
    "key, subkey = jrn.split(key)\n",
    "initial_mean, (initial_diag, initial_off_diag) = forward_model_markov_process(\n",
    "    z_la, x0, A_t, B, Sigma, Omega_la\n",
    ")\n",
    "# getting XLA error otherwise\n",
    "with jax.default_device(jax.devices(\"cpu\")[0]):\n",
    "    (true_diag, true_off_diag, true_mu), (_, log_weights_ce), _ = ce_cholesky_precision(\n",
    "        Y,\n",
    "        x0,\n",
    "        A_t,\n",
    "        Sigma,\n",
    "        B,\n",
    "        xi,\n",
    "        dist,\n",
    "        initial_mean,\n",
    "        initial_diag,\n",
    "        initial_off_diag,\n",
    "        1,\n",
    "        N_true,\n",
    "        subkey,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "single_N_run_ce = partial(\n",
    "    ce_outcomes,\n",
    "    Y=Y,\n",
    "    key=subkey_run,\n",
    "    N_mse=M,\n",
    "    true_mean=true_mu,\n",
    "    true_diag=true_diag,\n",
    "    true_off_diag=true_off_diag,\n",
    "    x0=x0,\n",
    "    A=A_t,\n",
    "    Sigma=Sigma,\n",
    "    B=B,\n",
    "    dist=dist,\n",
    "    xi=xi,\n",
    "    z_la=z_la,\n",
    "    Omega_la=Omega_la,\n",
    ")\n",
    "\n",
    "results_ce = pd.concat([single_N_run_ce(N) for N in Ns]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## inspect true solutions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, log_weights_eis = lcssm_importance_sampling(\n",
    "    Y, x0, A_t, Sigma, B, dist, xi, true_z_eis, true_omega_eis, N_true, subkey\n",
    ")\n",
    "ess_pct(log_weights_la), ess_pct(log_weights_ce), ess_pct(log_weights_eis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ce_true_mu, ce_true_var = marginals(true_mu, true_diag, true_off_diag)\n",
    "eis_true_mu, eis_true_var = eis_marginals(x0, A_t, Sigma, B, true_z_eis, true_omega_eis)\n",
    "la_mu, la_var = eis_marginals(x0, A_t, Sigma, B, z_la, Omega_la)\n",
    "\n",
    "\n",
    "fig, axs = plt.subplots(1, 2, figsize=(14, 6))\n",
    "\n",
    "axs[0].set_title(\"Mean\")\n",
    "axs[0].plot(la_mu[:, 0], label=\"LA\")\n",
    "axs[0].plot(ce_true_mu[:, 0], label=\"CE\")\n",
    "axs[0].plot(eis_true_mu[:, 0], label=\"EIS\")\n",
    "axs[0].legend()\n",
    "axs[1].set_title(\"marginal variances\")\n",
    "axs[1].plot(la_var[:, 0], label=\"LA\")\n",
    "axs[1].plot(ce_true_var[:, 0], label=\"CE\")\n",
    "axs[1].plot(eis_true_var[:, 0], label=\"EIS\")\n",
    "axs[1].legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## simulation results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "results_eis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.concat(\n",
    "    [\n",
    "        results_la.assign(method=\"LA\"),\n",
    "        results_eis.assign(method=\"EIS\"),\n",
    "        results_ce.assign(method=\"CE\"),\n",
    "    ]\n",
    ")\n",
    "results.to_csv(\n",
    "    here() / \"data/figures/03_state_space_models/compare_ce_eis_mse.csv\", index=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_eis[\"N\"] = results_eis[\"N\"].astype(jnp.float64)\n",
    "sns.boxplot(results_eis, x=\"N\", y=\"ef\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimum analysis: efficiency factors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ef = pd.DataFrame({\"N\": {}, \"method\": {}, \"ef\": {}})\n",
    "(n_iter_la, n_iter_eis, n_iter_ce) = (10, 10, 10)\n",
    "\n",
    "key, *subkeys_large = jrn.split(key, 3)\n",
    "subkeys_large = jnp.array(subkeys_large)\n",
    "\n",
    "for subkey in subkeys_large:\n",
    "    n = 10\n",
    "    N_true = int(1.5 * 1e6 / n)\n",
    "    x0 = jnp.zeros(1)\n",
    "    alpha = 0.5\n",
    "    A = alpha * jnp.tile(jnp.eye(1)[None, :, :], (n, 1, 1))\n",
    "    Sigma = (1 - alpha**2) * jnp.tile(jnp.eye(1)[None, :, :], (n + 1, 1, 1))\n",
    "\n",
    "    # NB observations\n",
    "    model = nb_lcssm(x0, A, Sigma, jnp.tile(jnp.eye(1)[None, :, :], (n + 1, 1, 1)), 0.1)\n",
    "    # model = poisson_lcssm(\n",
    "    #    x0,\n",
    "    #    A,\n",
    "    #    Sigma,\n",
    "    #    jnp.tile(jnp.eye(1)[None, :,:], (n + 1, 1, 1)),\n",
    "    # )\n",
    "    x0, A, Sigma, B, dist, xi = model\n",
    "\n",
    "    key, subkey = jrn.split(key)\n",
    "    (X,), (Y,) = simulate_lcssm(*model, 1, subkey)\n",
    "    X_smooth, z_la, Omega_la = mode_estimation(\n",
    "        Y, x0, A, Sigma, B, dist, xi, X, n_iter_la\n",
    "    )\n",
    "    true_z_eis, true_omega_eis = modified_efficient_importance_sampling(\n",
    "        Y,\n",
    "        x0,\n",
    "        A,\n",
    "        Sigma,\n",
    "        B,\n",
    "        xi,\n",
    "        dist,\n",
    "        z_la,\n",
    "        Omega_la,\n",
    "        n_iter_eis,\n",
    "        N_true,\n",
    "        subkey,\n",
    "    )\n",
    "\n",
    "    log_weights_eis = log_weights_ssm(\n",
    "        Y, x0, A, B, Sigma, true_z_eis, true_omega_eis, dist, xi, N_true, subkey\n",
    "    )\n",
    "\n",
    "    log_weights_la = log_weights_ssm(\n",
    "        Y, x0, A, B, Sigma, z_la, Omega_la, dist, xi, N_true, subkey\n",
    "    )\n",
    "    # _, log_weights_la = lcssm_importance_sampling(\n",
    "    #    Y, x0, A, Sigma, B, dist, xi, z_la, Omega_la, N_true, subkey\n",
    "    # )\n",
    "\n",
    "    key, subkey = jrn.split(key)\n",
    "\n",
    "    initial_mean, (initial_diag, initial_off_diag) = forward_model_markov_process(\n",
    "        z_la, x0, A, B, Sigma, Omega_la\n",
    "    )\n",
    "    _, (_, log_weights_ce), _ = ce_cholesky_precision(\n",
    "        Y,\n",
    "        x0,\n",
    "        A,\n",
    "        Sigma,\n",
    "        B,\n",
    "        xi,\n",
    "        dist,\n",
    "        initial_mean,\n",
    "        initial_diag,\n",
    "        initial_off_diag,\n",
    "        n_iter_ce,\n",
    "        N_true,\n",
    "        subkey,\n",
    "    )\n",
    "\n",
    "    df_ef = pd.concat(\n",
    "        [\n",
    "            df_ef,\n",
    "            pd.DataFrame(\n",
    "                {\n",
    "                    \"N\": N_true,\n",
    "                    \"method\": [\"LA\", \"EIS\", \"CE\"],\n",
    "                    \"ef\": [\n",
    "                        ess_pct(log_weights_la),\n",
    "                        ess_pct(log_weights_eis),\n",
    "                        ess_pct(log_weights_ce),\n",
    "                    ],\n",
    "                }\n",
    "            ),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "df_ef.to_csv(here() / \"data/figures/03_state_space_models/ef_large_N.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_state_dimensions = pd.DataFrame({\"N\": {}, \"m\": {}, \"n\": {}, \"method\": {}, \"ef\": {}})\n",
    "\n",
    "(n_iter_la, n_iter_eis, n_iter_ce) = (100, 100, 100)\n",
    "\n",
    "M = 3\n",
    "key, *subkeys_large = jrn.split(key, M + 1)\n",
    "subkeys_large = jnp.array(subkeys_large)\n",
    "\n",
    "ms = jnp.array([2, 4, 8, 16, 32])\n",
    "n = 10\n",
    "\n",
    "progress_bar = IntProgress(min=0, max=M * len(ms))\n",
    "display(progress_bar)\n",
    "\n",
    "for j in range(M):\n",
    "    key = subkeys_large[j]\n",
    "    for m in ms:\n",
    "        progress_bar.description = f\"m={m}({j+1}/{M})\"\n",
    "\n",
    "        # prevent OOM, smaller N for larger n\n",
    "        N_true = int(1e6)\n",
    "        x0 = jnp.zeros(m)\n",
    "        alpha = 0.5\n",
    "        A = alpha * jnp.tile(jnp.eye(m)[None, :, :], (n, 1, 1))\n",
    "        key, subkey = jrn.split(key)\n",
    "        innovation_cov = Wishart(df=1.1 * m, scale_tril=jnp.eye(m)).sample(seed=subkey)\n",
    "        Sigma = 1 / (1 - alpha**2) * jnp.tile(innovation_cov[None, :, :], (n + 1, 1, 1))\n",
    "\n",
    "        # NB observations\n",
    "        model = nb_lcssm(\n",
    "            x0, A, Sigma, jnp.tile(jnp.eye(m)[None, :, :], (n + 1, 1, 1)), 0.1\n",
    "        )\n",
    "        x0, A, Sigma, B, dist, xi = model\n",
    "\n",
    "        key, subkey = jrn.split(key)\n",
    "        (X,), (Y,) = simulate_lcssm(*model, 1, subkey)\n",
    "\n",
    "        s_init = vmap(jnp.dot)(B, X)\n",
    "        X_smooth, z_la, Omega_la = mode_estimation(\n",
    "            Y, x0, A, Sigma, B, dist, xi, s_init, n_iter_la\n",
    "        )\n",
    "\n",
    "        key, subkey = jrn.split(key)\n",
    "        true_z_eis, true_omega_eis = modified_efficient_importance_sampling(\n",
    "            Y,\n",
    "            x0,\n",
    "            A,\n",
    "            Sigma,\n",
    "            B,\n",
    "            xi,\n",
    "            dist,\n",
    "            z_la,\n",
    "            Omega_la,\n",
    "            n_iter_ce,\n",
    "            N_true,\n",
    "            subkey,\n",
    "        )\n",
    "\n",
    "        key, subkey = jrn.split(key)\n",
    "\n",
    "        log_weights_la = log_weights_ssm(\n",
    "            Y, x0, A, B, Sigma, z_la, Omega_la, dist, xi, N_true, subkey\n",
    "        )\n",
    "        log_weights_eis = log_weights_ssm(\n",
    "            Y, x0, A, B, Sigma, true_z_eis, true_omega_eis, dist, xi, N_true, subkey\n",
    "        )\n",
    "        # large simulations don't fit on GPU (yet)\n",
    "        with jax.default_device(jax.devices(\"cpu\")[0]):\n",
    "            initial_mean, (initial_diag, initial_off_diag) = (\n",
    "                forward_model_markov_process(z_la, x0, A, B, Sigma, Omega_la)\n",
    "            )\n",
    "            # with jax.default_device(jax.devices(\"cpu\")[0]):\n",
    "            _, (_, log_weights_ce), _ = ce_cholesky_precision(\n",
    "                Y,\n",
    "                x0,\n",
    "                A,\n",
    "                Sigma,\n",
    "                B,\n",
    "                xi,\n",
    "                dist,\n",
    "                initial_mean,\n",
    "                initial_diag,\n",
    "                initial_off_diag,\n",
    "                n_iter_ce,\n",
    "                N_true,\n",
    "                subkey,\n",
    "            )\n",
    "\n",
    "        df_state_dimensions = pd.concat(\n",
    "            [\n",
    "                df_state_dimensions,\n",
    "                pd.DataFrame(\n",
    "                    {\n",
    "                        \"N\": N_true,\n",
    "                        \"m\": m,\n",
    "                        \"j\": j,\n",
    "                        \"n\": n,\n",
    "                        \"method\": [\"LA\", \"EIS\", \"CE\"],\n",
    "                        \"ef\": [\n",
    "                            ess_pct(log_weights_la),\n",
    "                            ess_pct(log_weights_eis),\n",
    "                            ess_pct(log_weights_ce),\n",
    "                        ],\n",
    "                    }\n",
    "                ),\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        df_state_dimensions.to_csv(\n",
    "            here() / \"data/figures/03_state_space_models/ef_state_dimensions.csv\",\n",
    "            index=False,\n",
    "        )\n",
    "        progress_bar.value += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from isssm.lcssm import poisson_lcssm\n",
    "\n",
    "df_dimensions = pd.DataFrame({\"N\": {}, \"m\": {}, \"n\": {}, \"method\": {}, \"ef\": {}})\n",
    "\n",
    "(n_iter_la, n_iter_eis, n_iter_ce) = (100, 100, 100)\n",
    "\n",
    "M = 100\n",
    "key, *subkeys_large = jrn.split(key, M + 1)\n",
    "subkeys_large = jnp.array(subkeys_large)\n",
    "\n",
    "ns = jnp.array([10, 20, 40, 80, 160])\n",
    "\n",
    "for j in range(M):\n",
    "    key = subkeys_large[j]\n",
    "    for n in ns:\n",
    "\n",
    "        # prevent OOM, smaller N for larger n\n",
    "        N_true = int(1e6)\n",
    "        x0 = jnp.zeros(1)\n",
    "        alpha = 0.5\n",
    "        A = alpha * jnp.tile(jnp.eye(1)[None, :, :], (n, 1, 1))\n",
    "        Sigma = (1 - alpha**2) * jnp.tile(jnp.eye(1)[None, :, :], (n + 1, 1, 1))\n",
    "\n",
    "        # NB observations\n",
    "        model = nb_lcssm(\n",
    "            x0, A, Sigma, jnp.tile(jnp.eye(1)[None, :, :], (n + 1, 1, 1)), 0.1\n",
    "        )\n",
    "        # model = poisson_lcssm(\n",
    "        #    x0,\n",
    "        #    A,\n",
    "        #    Sigma,\n",
    "        #    jnp.tile(jnp.eye(1)[None, :,:], (n + 1, 1, 1)),\n",
    "        # )\n",
    "        x0, A, Sigma, B, dist, xi = model\n",
    "\n",
    "        key, subkey = jrn.split(key)\n",
    "        (X,), (Y,) = simulate_lcssm(*model, 1, subkey)\n",
    "        n, m = X.shape\n",
    "\n",
    "        s_init = vmap(jnp.dot)(B, X)\n",
    "        X_smooth, z_la, Omega_la = mode_estimation(\n",
    "            Y, x0, A, Sigma, B, dist, xi, s_init, n_iter_la\n",
    "        )\n",
    "\n",
    "        key, subkey = jrn.split(key)\n",
    "        true_z_eis, true_omega_eis = modified_efficient_importance_sampling(\n",
    "            Y,\n",
    "            x0,\n",
    "            A,\n",
    "            Sigma,\n",
    "            B,\n",
    "            xi,\n",
    "            dist,\n",
    "            z_la,\n",
    "            Omega_la,\n",
    "            n_iter_ce,\n",
    "            N_true,\n",
    "            subkey,\n",
    "        )\n",
    "\n",
    "        key, subkey = jrn.split(key)\n",
    "\n",
    "        log_weights_la = log_weights_ssm(\n",
    "            Y, x0, A, B, Sigma, z_la, Omega_la, dist, xi, N_true, subkey\n",
    "        )\n",
    "        log_weights_eis = log_weights_ssm(\n",
    "            Y, x0, A, B, Sigma, true_z_eis, true_omega_eis, dist, xi, N_true, subkey\n",
    "        )\n",
    "        # large simulations don't fit on GPU (yet)\n",
    "        with jax.default_device(jax.devices(\"cpu\")[0]):\n",
    "            initial_mean, (initial_diag, initial_off_diag) = (\n",
    "                forward_model_markov_process(z_la, x0, A, B, Sigma, Omega_la)\n",
    "            )\n",
    "            # with jax.default_device(jax.devices(\"cpu\")[0]):\n",
    "            _, (_, log_weights_ce), _ = ce_cholesky_precision(\n",
    "                Y,\n",
    "                x0,\n",
    "                A,\n",
    "                Sigma,\n",
    "                B,\n",
    "                xi,\n",
    "                dist,\n",
    "                initial_mean,\n",
    "                initial_diag,\n",
    "                initial_off_diag,\n",
    "                n_iter_ce,\n",
    "                N_true,\n",
    "                subkey,\n",
    "            )\n",
    "\n",
    "        df_dimensions = pd.concat(\n",
    "            [\n",
    "                df_dimensions,\n",
    "                pd.DataFrame(\n",
    "                    {\n",
    "                        \"N\": N_true,\n",
    "                        \"m\": m,\n",
    "                        \"j\": j,\n",
    "                        \"n\": n,\n",
    "                        \"method\": [\"LA\", \"EIS\", \"CE\"],\n",
    "                        \"ef\": [\n",
    "                            ess_pct(log_weights_la),\n",
    "                            ess_pct(log_weights_eis),\n",
    "                            ess_pct(log_weights_ce),\n",
    "                        ],\n",
    "                    }\n",
    "                ),\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        df_dimensions.to_csv(\n",
    "            here() / \"data/figures/03_state_space_models/ef_dimensions.csv\", index=False\n",
    "        )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

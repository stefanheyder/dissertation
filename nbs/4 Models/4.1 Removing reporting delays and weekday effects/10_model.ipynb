{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "---\n",
    "skip_exec: true    # Skips in tests\n",
    "skip_showdoc: true # Skips in docs builds\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model for removing weekday effects and reporting delays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | default_exp models.reporting_delays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "import jax\n",
    "\n",
    "jax.config.update(\"jax_enable_x64\", True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "import jax.numpy as jnp\n",
    "import jax.scipy as jsp\n",
    "from pyprojroot.here import here\n",
    "import jax\n",
    "import jax.random as jrn\n",
    "from jax import vmap, jit\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "\n",
    "from isssm.typing import PGSSM, GLSSMState\n",
    "from jaxtyping import Array, Float\n",
    "\n",
    "from tensorflow_probability.substrates.jax.distributions import (\n",
    "    NegativeBinomial as NBinom,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "mpl.rcParams[\"figure.figsize\"] = (20, 6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tuning parameter for methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "n_iterations = 20\n",
    "N_mle = 1000\n",
    "N_meis = 1000\n",
    "N_posterior = 10000\n",
    "\n",
    "key = jrn.PRNGKey(34234234)\n",
    "\n",
    "# same as in FCH\n",
    "percentiles_of_interest = jnp.array(\n",
    "    [0.01, 0.025, *(0.05 * jnp.arange(1, 20)), 0.975, 0.99]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## States\n",
    "\n",
    "We consider states $X_t = \\left(\\log I_{t}, W_t, \\dots, W_{t - 5}, q_{1,t}, q_{2,t}, q_{3,t}\\right)$ with\n",
    "\n",
    "- $\\log I_{t + 1} = \\log I_{t} + \\log \\rho_{t}$\n",
    "- $\\log \\rho_{t + 1} = \\log \\rho_{t} + \\varepsilon^{\\rho}_{t + 1}$\n",
    "- $M_{t + 1} = -\\frac{1}{2}\\sigma^{2}_{2} + \\varepsilon^M_{t +1 } \\sim \\mathcal N (-\\frac{1}{2} \\sigma^{2}_M, \\sigma^{2}_M)$, \"muck\" term (s.t. $\\mathbf E M_{t + 1} = 1$)\n",
    "- $W_{t + 1} = - \\sum_{s = 0}^5 W_{t - s} + \\varepsilon^W_{t + 1}$ , $\\varepsilon^W_{t + 1} \\sim \\mathcal N(0, \\sigma^2_W)$\n",
    "- $q_{t,\\tau} = q_{t,\\tau} + \\varepsilon_{t + 1}^{q,\\tau}$; $\\tau = 1,2,3$\n",
    "\n",
    "\n",
    "Observations are the breakdown of incidences with Meldedatum $t$ into the delays $\\tau = 1, \\dots$. Note that on date $t$, $Y_t$ is only partially observed:\n",
    "$$\n",
    "Y^i_{t} \\sim \\operatorname{Pois} \\left( p_{t,\\tau}\\exp \\left( W_{t} + \\log I_{t} + M_{t}\\right)\\right) = \\operatorname{Pois} \\left( p_{t,\\tau} \\exp(W_{t} M_{t}) I_{t}\\right),\n",
    "$$\n",
    "for $\\tau = 1,\\dots, 4$, where the parametrization is such that the first parameter is the mean, the second the overdispersion parameter.\n",
    "\n",
    "Here \n",
    "$$\n",
    "    %p_{t,\\tau} = \\frac{\\exp \\left( q_{t,\\tau} \\right)}{\\sum_{j = 1}^{4}\\exp \\left( q_{j,t} \\right)}.\n",
    "    p_{t,\\tau} = \\frac{\\exp \\left( q_{t,\\tau} \\right)}{1 + \\sum_{j = 1}^{3}\\exp \\left( q_{j,t} \\right)},\n",
    "$$\n",
    "for $\\tau = 1, 2, 3$ and \n",
    "$$\n",
    "    p_{4, t} = \\frac{1}{1 + \\sum_{j = 1}^{3}\\exp \\left( q_{j,t} \\right)},\n",
    "$$\n",
    "similar as in Multinomial logistic regression.\n",
    "\n",
    "We let \n",
    "$$\n",
    "    \\begin{align*}\n",
    "    S_{t} &= B_{t}X_{t} \\\\\n",
    "    &= \\left( \\log I_{t} + \\log W_{t} + M_{t}, q_{1,t}, q_{2,t}, q_{3, t}\\right)\n",
    "    \\end{align*}\n",
    "$$\n",
    "\n",
    "Now \n",
    "$$\n",
    "    Y_{t}^\\tau | S_{t} \\sim \\operatorname{Pois} \\left( p_{t,\\tau}\\exp \\left( \\log I_{t} + \\log W_{t} + M_{t} \\right)\\right).\n",
    "$$\n",
    "Note the following:\n",
    "\n",
    "- $Y_t^\\tau$ depends on all signals, not just on one, however the observations are still conditionally independent\n",
    "\n",
    "\n",
    "The parameter $\\theta$ of this model is \n",
    "$$\n",
    "    \\theta = \\left( \\log \\sigma^{2}_{\\log \\rho}, \\log \\sigma^{2}_{W}, \\log \\sigma^{2}_q , \\log \\sigma^{2}_{M}\\right).\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "# Model\n",
    "from isssm.typing import PGSSM\n",
    "import jax.scipy.linalg as jsla\n",
    "from tensorflow_probability.substrates.jax.distributions import Poisson\n",
    "from ssm4epi.models.util import to_log_probs\n",
    "\n",
    "\n",
    "def _model(theta, aux):\n",
    "    # theta on log scale\n",
    "    s2_log_r, s2_W, s2_q, s2_M, s2_Wq = jnp.exp(theta)\n",
    "    np1, n_delay = aux\n",
    "\n",
    "    n = np1 - 1\n",
    "    m = 3 + 6 + (n_delay - 1) + 3 * 6\n",
    "    p = n_delay\n",
    "    l = 3 + (n_delay - 1) + 3\n",
    "\n",
    "    # states\n",
    "    u = jnp.zeros((np1, m))\n",
    "    u = u.at[:, 2].set(-1 / 2 * s2_M)  # force exp(M_t) to have mean 1\n",
    "\n",
    "    A_I_rho = jnp.array([[1.0, 1.0], [0.0, 1.0]])\n",
    "    A_M = jnp.zeros((1, 1))  # muck\n",
    "    A_W = jnp.array(\n",
    "        [\n",
    "            [-1.0, -1.0, -1.0, -1.0, -1.0, -1.0],\n",
    "            [1.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
    "            [0.0, 1.0, 0.0, 0.0, 0.0, 0.0],\n",
    "            [0.0, 0.0, 1.0, 0.0, 0.0, 0.0],\n",
    "            [0.0, 0.0, 0.0, 1.0, 0.0, 0.0],\n",
    "            [0.0, 0.0, 0.0, 0.0, 1.0, 0.0],\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    A_q = jnp.eye(n_delay - 1)\n",
    "    # A_q = jnp.block(\n",
    "    #    [\n",
    "    #        [jnp.zeros((n_delay - 1, 6 * (n_delay - 1))), jnp.eye(n_delay - 1)],\n",
    "    #        [jnp.eye(6 * (n_delay - 1)), jnp.zeros((6 * (n_delay - 1), n_delay - 1))],\n",
    "    #    ]\n",
    "    # )\n",
    "    A = jsla.block_diag(A_I_rho, A_M, A_W, A_q, A_W, A_W, A_W)\n",
    "    v = jnp.zeros((np1, p))\n",
    "\n",
    "    D = jnp.eye(m)[\n",
    "        :,\n",
    "        jnp.array(\n",
    "            [\n",
    "                1,\n",
    "                2,\n",
    "                3,\n",
    "                *jnp.arange(3 + 6, 3 + 6 + n_delay - 1),\n",
    "                *(3 + 6 + n_delay - 1 + jnp.arange(0, 3 * 6, 6)),\n",
    "            ]\n",
    "        ),\n",
    "    ]\n",
    "\n",
    "    Sigma = jnp.diag(\n",
    "        jnp.array(\n",
    "            [\n",
    "                s2_log_r,\n",
    "                s2_M,\n",
    "                s2_W,\n",
    "                *jnp.repeat(s2_q, n_delay - 1),\n",
    "                *jnp.repeat(s2_Wq, 3),\n",
    "            ]\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # large initial variance, diffuse initialization\n",
    "    Sigma0 = jsla.block_diag(\n",
    "        25 * jnp.eye(1),  # log I,\n",
    "        0.2**2 * jnp.eye(1),  # log rho,\n",
    "        s2_M * jnp.eye(1),  # D\n",
    "        1 * jnp.eye(6),  # W\n",
    "        1 * jnp.eye((n_delay - 1)),  # q\n",
    "        1 * jnp.eye(3 * 6),  # Wq\n",
    "    )\n",
    "\n",
    "    B_logI = jnp.eye(n_delay)[:, :1]\n",
    "    B_logrho = jnp.zeros((n_delay, 1))\n",
    "    B_logM = jnp.eye(n_delay)[:, :1]\n",
    "    B_logW = jnp.hstack(\n",
    "        [\n",
    "            jnp.eye(n_delay)[:, :1],  # W_t\n",
    "            jnp.zeros((n_delay, 5)),  # W_t-s\n",
    "        ]\n",
    "    )\n",
    "    B_q = jnp.eye(n_delay)[:, 1:]\n",
    "    B_Wq = jnp.hstack(\n",
    "        [\n",
    "            jnp.eye(n_delay)[:, 1:2],\n",
    "            jnp.zeros((n_delay, 5)),  # W_t-s\n",
    "            jnp.eye(n_delay)[:, 2:3],\n",
    "            jnp.zeros((n_delay, 5)),  # W_t-s\n",
    "            jnp.eye(n_delay)[:, 3:],\n",
    "            jnp.zeros((n_delay, 5)),  # W_t-s\n",
    "        ]\n",
    "    )\n",
    "    B = jnp.hstack(\n",
    "        [\n",
    "            B_logI,\n",
    "            B_logrho,\n",
    "            B_logM,\n",
    "            B_logW,\n",
    "            B_q,\n",
    "            B_Wq,\n",
    "            # jnp.zeros((n_delay, 6 * (n_delay - 1))),  # q_t-s\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    A = jnp.broadcast_to(A, (n, m, m))\n",
    "    D = jnp.broadcast_to(D, (n, m, l))\n",
    "    Sigma = jnp.broadcast_to(Sigma, (n, l, l))\n",
    "    B = jnp.broadcast_to(B, (np1, p, m))\n",
    "\n",
    "    def poisson_obs(s, xi):\n",
    "        log_I_W, q = jnp.split(s, [1], axis=-1)\n",
    "        log_p = to_log_probs(q)\n",
    "        log_rate = log_I_W + log_p\n",
    "        return Poisson(log_rate=log_rate)\n",
    "\n",
    "    def negbinom_obs(s, xi):\n",
    "        log_I_W, q = jnp.split(s, [1], axis=-1)\n",
    "        log_p = to_log_probs(q)\n",
    "        log_mu = log_I_W + log_p\n",
    "        return NBinom(r, logits=log_mu - jnp.log(r))\n",
    "\n",
    "    dist = poisson_obs  # negbinom_obs\n",
    "    xi = jnp.empty((np1, p, 1))\n",
    "\n",
    "    return PGSSM(u, A, D, Sigma0, Sigma, v, B, dist, xi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `isssm.laplace_approximation` module assumes that $y_{t,i}$ only depends on $\\theta_{t,i}$ which is not the case here. To fix this, we monkey-patch both the LA and MEIS.\n",
    "\n",
    "Additionaly, we have to account for missing values in both methods. If $y_t$ is missing, we transform the model to be \n",
    "$$\n",
    "    y_{t} | s_{t} ~ \\delta_{s_{t}}\n",
    "$$\n",
    "and $B_t x_t = s_t = 0$. Then $\\log p(y_{t} | s_{t}) = 0$ for all $s_t$, with gradient $0_{p}$ and Hessian $0_{p \\times p}$. For any initial value of $s_t$ the LA observation is \n",
    "$$\n",
    "    z_{t} =  s_{t} + \\underbrace{\\ddot p(y_{t}|s_{t})}_{= 0_{p \\times p}}~ ^{\\dagger} \\underbrace{\\dot p(y_{t}| s_{t})}_{= 0_{p}} = s_{t} \n",
    "$$\n",
    "with covariance matrix\n",
    "$$\n",
    "    \\Omega_{t} = \\ddot p(y_{t} | s_{t})^{\\dagger} = 0_{p\\times p}.\n",
    "$$\n",
    "which keeps $s_t$ constant. Here $\\dagger$ indicates the Moore-Penrose generalized inverse. Thus setting $s_{t} = 0$, this results in a GLSSM where $y_t$ is as if it is missing.\n",
    "\n",
    "For EIS, the pseudo-observations in the WLS are $\\log p(y_{t} | s_{t}^i) = 0$, by a similar argument. Thus the estimates are $\\hat\\beta_{t} = 0_{2p + 1}$, and, taking pseudo-inverses again, we arrive at the same conclusion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "def account_for_nans(model: PGSSM, y, missing_indices) -> tuple[PGSSM, Float]:\n",
    "    # only works for Poisson!\n",
    "    # missing_indices = jnp.isnan(y)\n",
    "\n",
    "    y_missing = jnp.nan_to_num(y, nan=0.0)\n",
    "\n",
    "    v = model.v.at[missing_indices].set(0.0)\n",
    "    B = model.B.at[missing_indices].set(0.0)\n",
    "\n",
    "    xi_missing = jnp.ones_like(y).at[missing_indices].set(0.0)[..., None]\n",
    "    xi = jnp.concatenate([xi_missing, model.xi], -1)\n",
    "\n",
    "    def missing_dist(s, xi):\n",
    "        xi_missing, old_xi = xi[..., 0], xi[..., 1:]\n",
    "        old_dist = model.dist(s, old_xi)\n",
    "        # if xi == 0. the log rate becomes -inf, so dist is dirac_0\n",
    "        return Poisson(log_rate=old_dist.log_rate + jnp.log(xi_missing))\n",
    "\n",
    "    model_missing = PGSSM(\n",
    "        u=model.u,\n",
    "        A=model.A,\n",
    "        D=model.D,\n",
    "        Sigma0=model.Sigma0,\n",
    "        Sigma=model.Sigma,\n",
    "        v=v,\n",
    "        B=B,\n",
    "        dist=missing_dist,\n",
    "        xi=xi,\n",
    "    )\n",
    "\n",
    "    return model_missing, y_missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(here() / \"data/processed/RKI_4day_rt.csv\")\n",
    "i_start = 0\n",
    "np1 = 150\n",
    "data_selected = df.iloc[i_start : i_start + np1, 1:]\n",
    "dates = pd.to_datetime(df.iloc[i_start : i_start + np1, 0])\n",
    "y = jnp.asarray(data_selected.to_numpy())\n",
    "\n",
    "plt.plot(dates, y)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from isssm.importance_sampling import pgssm_importance_sampling, ess_pct\n",
    "from jax import random as jrn\n",
    "from ssm4epi.models.util import visualize_pgssm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "theta_manual = jnp.log(\n",
    "    # s2_log_rho, s2_W, s2_q, s2_D\n",
    "    jnp.array([0.001**2, 0.1**2, 0.5**2, 0.01**2, 0.1**2])\n",
    ")\n",
    "\n",
    "# allow variance to be larger as mean\n",
    "aux = (np1, 4)\n",
    "pgssm = _model(theta_manual, aux)\n",
    "\n",
    "visualize_pgssm(pgssm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Monkey patching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "# LA monkey patch\n",
    "from isssm.kalman import kalman, smoothed_signals\n",
    "from isssm.typing import GLSSM, GLSSMProposal, ConvergenceInformation\n",
    "from isssm.laplace_approximation import default_link, vvmap, vdiag\n",
    "from jax.scipy.optimize import minimize\n",
    "from functools import partial\n",
    "from isssm.util import converged\n",
    "from jax import jacfwd, hessian, jacrev\n",
    "from jax.lax import while_loop\n",
    "import isssm.laplace_approximation\n",
    "\n",
    "\n",
    "def _initial_guess(xi_t, y_t, dist, link=default_link):\n",
    "    return jnp.array([jnp.log(y_t.sum() + 1), *jnp.zeros(3)])\n",
    "\n",
    "\n",
    "isssm.laplace_approximation._initial_guess = _initial_guess\n",
    "from ssm4epi.patch import full_deps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from isssm.laplace_approximation import laplace_approximation\n",
    "from isssm.modified_efficient_importance_sampling import (\n",
    "    modified_efficient_importance_sampling as MEIS,\n",
    ")\n",
    "\n",
    "key = jrn.PRNGKey(123423423)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from isssm.estimation import mle_pgssm, initial_theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_result = initial_theta(y, _model, theta_manual, aux, 20)\n",
    "theta0 = initial_result.x\n",
    "initial_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# key, subkey = jrn.split(key)\n",
    "# mle_result = mle_pgssm(y, _model, theta0, aux, 20, 1000, subkey)\n",
    "# theta_hat = mle_result.x\n",
    "# mle_result\n",
    "\n",
    "theta_hat = theta0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_manual = jnp.exp(theta_manual / 2)\n",
    "s_0 = jnp.exp(theta0 / 2)\n",
    "\n",
    "k = theta_manual.size\n",
    "plt.scatter(jnp.arange(k) - 0.2, s_manual, label=\"Manual\")\n",
    "plt.scatter(jnp.arange(k), s_0, label=\"Initial\")\n",
    "s_mle = jnp.exp(theta_hat / 2)\n",
    "plt.scatter(jnp.arange(k) + 0.2, s_mle, label=\"MLE\")\n",
    "plt.xticks(jnp.arange(k), [\"$\\\\log \\\\rho$\", \"$W$\", \"$q$\", \"D\", \"Wq\"])\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fitted_model = _model(theta0, aux)\n",
    "\n",
    "proposal_la, _ = laplace_approximation(y, fitted_model, 100)\n",
    "key, subkey = jrn.split(key)\n",
    "proposal_meis, _ = MEIS(\n",
    "    y, fitted_model, proposal_la.z, proposal_la.Omega, 10, int(1e4), subkey\n",
    ")\n",
    "\n",
    "key, subkey = jrn.split(key)\n",
    "samples_meis, log_weights_meis = pgssm_importance_sampling(\n",
    "    y, fitted_model, proposal_meis.z, proposal_meis.Omega, 10000, subkey\n",
    ")\n",
    "key, subkey = jrn.split(key)\n",
    "samples_la, log_weights_la = pgssm_importance_sampling(\n",
    "    y, fitted_model, proposal_la.z, proposal_la.Omega, 10000, subkey\n",
    ")\n",
    "ess_pct(log_weights_la), ess_pct(log_weights_meis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from isssm.importance_sampling import normalize_weights, mc_integration\n",
    "from isssm.typing import GLSSM\n",
    "from isssm.kalman import kalman, smoother, state_mode\n",
    "from isssm.laplace_approximation import posterior_mode\n",
    "from isssm.util import mm_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "signal_la = posterior_mode(proposal_la)\n",
    "\n",
    "state_modes_meis = vmap(state_mode, (None, 0))(fitted_model, samples_meis)\n",
    "x_smooth = mc_integration(state_modes_meis, log_weights_meis)\n",
    "\n",
    "x_smooth_la = state_mode(fitted_model, signal_la)\n",
    "\n",
    "# plt.plot(jnp.exp(x_smooth[:, 12]), label=\"smoothed\")\n",
    "# plt.plot(jnp.exp(x_smooth[:, 2:8].sum(axis=1)), label=\"smoothed\")\n",
    "# plt.plot(jnp.exp(x_smooth[:, 0]), label=\"smoothed\")\n",
    "# plt.plot(y.sum(axis=1), label=\"Y\")\n",
    "# plt.plot(jnp.exp(x_smooth[:, 1]), label=\"smoothed\")\n",
    "\n",
    "I_smooth = jnp.exp(x_smooth[:, 0])\n",
    "I_smooth_LA = jnp.exp(x_smooth_la[:, 0])\n",
    "\n",
    "rho_smooth = jnp.exp(x_smooth[:, 1])\n",
    "rho_smooth_LA = jnp.exp(x_smooth_la[:, 1])\n",
    "\n",
    "D_smooth = jnp.exp(x_smooth[:, 2])\n",
    "D_smooth_LA = jnp.exp(x_smooth_la[:, 2])\n",
    "\n",
    "W_smooth = jnp.exp(x_smooth[:, 3])\n",
    "W_smooth_LA = jnp.exp(x_smooth_la[:, 3])\n",
    "\n",
    "log_ratios = x_smooth[:, 9:12]\n",
    "log_probs = to_log_probs(log_ratios)\n",
    "\n",
    "fig, axs = plt.subplots(4, 2, figsize=(10, 10))\n",
    "\n",
    "axs = axs.flatten()\n",
    "fig.tight_layout()\n",
    "\n",
    "axs[0].set_title(\"incidences\")\n",
    "axs[0].plot(dates, I_smooth, label=\"$I_t$\")\n",
    "axs[0].plot(dates, I_smooth_LA, label=\"$I_t$ LA\")\n",
    "axs[0].plot(dates, y.sum(axis=1), label=\"$Y_t$\")\n",
    "axs[0].legend()\n",
    "\n",
    "axs[1].set_title(\"growth factor\")\n",
    "axs[1].plot(dates, rho_smooth, label=\"$\\\\log \\\\rho_t$\")\n",
    "axs[1].plot(dates, rho_smooth_LA, label=\"$\\\\log \\\\rho_t$ LA\")\n",
    "\n",
    "axs[2].set_title(\"weekday effect\")\n",
    "axs[2].plot(dates, W_smooth, label=\"$W_t$\")\n",
    "axs[2].plot(dates, W_smooth_LA, label=\"$W_t$ LA\")\n",
    "\n",
    "axs[3].set_title(\"delay probabilities\")\n",
    "\n",
    "\n",
    "axs[3].plot(dates, jnp.exp(log_probs[:, 0]), label=\"$p_{t, 1}$\")\n",
    "axs[3].plot(dates, jnp.exp(log_probs[:, 1]), label=\"$p_{t, 2}$\")\n",
    "axs[3].plot(dates, jnp.exp(log_probs[:, 2]), label=\"$p_{t, 3}$\")\n",
    "axs[3].plot(dates, jnp.exp(log_probs[:, 3]), label=\"$p_{t, 4}$\")\n",
    "axs[3].plot(dates, jnp.exp(log_probs).sum(axis=1), label=\"total p\")\n",
    "axs[3].legend()\n",
    "\n",
    "axs[4].set_title(\"Log ratios\")\n",
    "axs[4].plot(dates, log_ratios[:, 0], label=\"$q_{t, 1}$\")\n",
    "axs[4].plot(dates, log_ratios[:, 1], label=\"$q_{t, 2}$\")\n",
    "axs[4].plot(dates, log_ratios[:, 2], label=\"$q_{t, 3}$\")\n",
    "for d in dates[::7]:\n",
    "    axs[4].axvline(d, color=\"black\", alpha=0.2)\n",
    "\n",
    "axs[5].set_title(\"Dirt\")\n",
    "axs[5].plot(dates, D_smooth)\n",
    "\n",
    "axs[6].set_title(\"Weekday log_ratios\")\n",
    "axs[6].plot(dates, x_smooth[:, jnp.array([13, 19, 25])])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Christmas period model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dates.iloc[110]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "christmas_inds = jnp.arange(75, 110)\n",
    "y_nans = y.astype(jnp.float64).at[christmas_inds].set(jnp.nan)\n",
    "christmas_inds = jnp.isnan(y_nans)\n",
    "_model_miss = lambda theta, aux: account_for_nans(\n",
    "    _model(theta, aux), y_nans, christmas_inds\n",
    ")[0]\n",
    "theta0_miss = initial_theta(y_miss, _model_miss, theta_manual, aux, 100)\n",
    "model_miss, y_miss = account_for_nans(\n",
    "    _model(theta0_miss.x, aux), y_nans, christmas_inds\n",
    ")\n",
    "proposal_la_miss, _ = laplace_approximation(y_miss, model_miss, 100)\n",
    "key, subkey = jrn.split(key)\n",
    "proposal_meis_miss, _ = MEIS(\n",
    "    y_miss, model_miss, proposal_la_miss.z, proposal_la_miss.Omega, 10, 4000, subkey\n",
    ")\n",
    "\n",
    "key, subkey = jrn.split(key)\n",
    "missing_samples, missing_log_weights = pgssm_importance_sampling(\n",
    "    y_miss,\n",
    "    model_miss,\n",
    "    proposal_meis_miss.z,\n",
    "    proposal_meis.Omega,\n",
    "    1000,\n",
    "    subkey,\n",
    ")\n",
    "ess_pct(missing_log_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ess_pct(missing_log_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_smooth = (\n",
    "    # vmap(smooth_x)(samples_la) * normalize_weights(log_weights_la)[:, None, None]\n",
    "    vmap(state_mode, (None, 0))(model_miss, missing_samples)\n",
    "    * normalize_weights(missing_log_weights)[:, None, None]\n",
    ").sum(axis=0)\n",
    "\n",
    "\n",
    "# plt.plot(jnp.exp(x_smooth[:, 12]), label=\"smoothed\")\n",
    "# plt.plot(jnp.exp(x_smooth[:, 2:8].sum(axis=1)), label=\"smoothed\")\n",
    "# plt.plot(jnp.exp(x_smooth[:, 0]), label=\"smoothed\")\n",
    "# plt.plot(y.sum(axis=1), label=\"Y\")\n",
    "# plt.plot(jnp.exp(x_smooth[:, 1]), label=\"smoothed\")\n",
    "\n",
    "I_smooth = jnp.exp(x_smooth[:, 0])\n",
    "I_smooth_LA = jnp.exp(x_smooth_la[:, 0])\n",
    "\n",
    "rho_smooth = jnp.exp(x_smooth[:, 1])\n",
    "rho_smooth_LA = jnp.exp(x_smooth_la[:, 1])\n",
    "\n",
    "D_smooth = jnp.exp(x_smooth[:, 2])\n",
    "D_smooth_LA = jnp.exp(x_smooth_la[:, 2])\n",
    "\n",
    "W_smooth = jnp.exp(x_smooth[:, 3])\n",
    "W_smooth_LA = jnp.exp(x_smooth_la[:, 3])\n",
    "\n",
    "log_ratios = x_smooth[:, 9:12]\n",
    "log_probs = to_log_probs(log_ratios)\n",
    "\n",
    "fig, axs = plt.subplots(3, 2, figsize=(10, 10))\n",
    "\n",
    "axs = axs.flatten()\n",
    "fig.tight_layout()\n",
    "\n",
    "axs[0].set_title(\"incidences\")\n",
    "axs[0].plot(dates, I_smooth, label=\"$I_t$\")\n",
    "axs[0].plot(dates, I_smooth_LA, label=\"$I_t$ LA\")\n",
    "axs[0].plot(dates, y.sum(axis=1), label=\"$Y_t$\")\n",
    "axs[0].legend()\n",
    "\n",
    "axs[1].set_title(\"growth factor\")\n",
    "axs[1].plot(dates, rho_smooth, label=\"$\\\\log \\\\rho_t$\")\n",
    "axs[1].plot(dates, rho_smooth_LA, label=\"$\\\\log \\\\rho_t$ LA\")\n",
    "\n",
    "axs[2].set_title(\"weekday effect\")\n",
    "axs[2].plot(dates, W_smooth, label=\"$W_t$\")\n",
    "axs[2].plot(dates, W_smooth_LA, label=\"$W_t$ LA\")\n",
    "\n",
    "axs[3].set_title(\"delay probabilities\")\n",
    "\n",
    "\n",
    "axs[3].plot(dates, jnp.exp(log_probs[:, 0]), label=\"$p_{t, 1}$\")\n",
    "axs[3].plot(dates, jnp.exp(log_probs[:, 1]), label=\"$p_{t, 2}$\")\n",
    "axs[3].plot(dates, jnp.exp(log_probs[:, 2]), label=\"$p_{t, 3}$\")\n",
    "axs[3].plot(dates, jnp.exp(log_probs[:, 3]), label=\"$p_{t, 4}$\")\n",
    "axs[3].plot(dates, jnp.exp(log_probs).sum(axis=1), label=\"total p\")\n",
    "axs[3].legend()\n",
    "\n",
    "axs[4].set_title(\"Log ratios\")\n",
    "axs[4].plot(dates, log_ratios[:, 0], label=\"$q_{t, 1}$\")\n",
    "axs[4].plot(dates, log_ratios[:, 1], label=\"$q_{t, 2}$\")\n",
    "axs[4].plot(dates, log_ratios[:, 2], label=\"$q_{t, 3}$\")\n",
    "for d in dates[::7]:\n",
    "    axs[4].axvline(d, color=\"black\", alpha=0.2)\n",
    "\n",
    "axs[5].set_title(\"Dirt\")\n",
    "axs[5].plot(dates, D_smooth)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | hide\n",
    "import nbdev\n",
    "\n",
    "nbdev.nbdev_export()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

# AUTOGENERATED! DO NOT EDIT! File to edit: ../../nbs/4 Models/4.1 Removing reporting delays and weekday effects/10_model.ipynb.

# %% auto 0
__all__ = ['n_iterations', 'N_mle', 'N_meis', 'N_posterior', 'key', 'percentiles_of_interest', 'account_for_nans']

# %% ../../nbs/4 Models/4.1 Removing reporting delays and weekday effects/10_model.ipynb 2
import jax

jax.config.update("jax_enable_x64", True)

# %% ../../nbs/4 Models/4.1 Removing reporting delays and weekday effects/10_model.ipynb 3
import jax.numpy as jnp
import jax.scipy as jsp
from pyprojroot.here import here
import jax
import jax.random as jrn
from jax import vmap, jit
import matplotlib.pyplot as plt
import matplotlib as mpl

from isssm.typing import PGSSM, GLSSMState
from jaxtyping import Array, Float

from tensorflow_probability.substrates.jax.distributions import (
    NegativeBinomial as NBinom,
)

# %% ../../nbs/4 Models/4.1 Removing reporting delays and weekday effects/10_model.ipynb 6
n_iterations = 20
N_mle = 1000
N_meis = 1000
N_posterior = 10000

key = jrn.PRNGKey(34234234)

# same as in FCH
percentiles_of_interest = jnp.array(
    [0.01, 0.025, *(0.05 * jnp.arange(1, 20)), 0.975, 0.99]
)

# %% ../../nbs/4 Models/4.1 Removing reporting delays and weekday effects/10_model.ipynb 8
# Model
from isssm.typing import PGSSM
import jax.scipy.linalg as jsla
from tensorflow_probability.substrates.jax.distributions import Poisson
from .util import to_log_probs


def _model(theta, aux):
    # theta on log scale
    s2_log_r, s2_W, s2_q, s2_M, s2_Wq = jnp.exp(theta)
    np1, n_delay = aux

    n = np1 - 1
    m = 3 + 6 + (n_delay - 1) + 3 * 6
    p = n_delay
    l = 3 + (n_delay - 1) + 3

    # states
    u = jnp.zeros((np1, m))
    u = u.at[:, 2].set(-1 / 2 * s2_M)  # force exp(M_t) to have mean 1

    A_I_rho = jnp.array([[1.0, 1.0], [0.0, 1.0]])
    A_M = jnp.zeros((1, 1))  # muck
    A_W = jnp.array(
        [
            [-1.0, -1.0, -1.0, -1.0, -1.0, -1.0],
            [1.0, 0.0, 0.0, 0.0, 0.0, 0.0],
            [0.0, 1.0, 0.0, 0.0, 0.0, 0.0],
            [0.0, 0.0, 1.0, 0.0, 0.0, 0.0],
            [0.0, 0.0, 0.0, 1.0, 0.0, 0.0],
            [0.0, 0.0, 0.0, 0.0, 1.0, 0.0],
        ]
    )

    A_q = jnp.eye(n_delay - 1)
    # A_q = jnp.block(
    #    [
    #        [jnp.zeros((n_delay - 1, 6 * (n_delay - 1))), jnp.eye(n_delay - 1)],
    #        [jnp.eye(6 * (n_delay - 1)), jnp.zeros((6 * (n_delay - 1), n_delay - 1))],
    #    ]
    # )
    A = jsla.block_diag(A_I_rho, A_M, A_W, A_q, A_W, A_W, A_W)
    v = jnp.zeros((np1, p))

    D = jnp.eye(m)[
        :,
        jnp.array(
            [
                1,
                2,
                3,
                *jnp.arange(3 + 6, 3 + 6 + n_delay - 1),
                *(3 + 6 + n_delay - 1 + jnp.arange(0, 3 * 6, 6)),
            ]
        ),
    ]

    Sigma = jnp.diag(
        jnp.array(
            [
                s2_log_r,
                s2_M,
                s2_W,
                *jnp.repeat(s2_q, n_delay - 1),
                *jnp.repeat(s2_Wq, 3),
            ]
        )
    )

    # large initial variance, diffuse initialization
    Sigma0 = jsla.block_diag(
        25 * jnp.eye(1),  # log I,
        0.2**2 * jnp.eye(1),  # log rho,
        s2_M * jnp.eye(1),  # D
        1 * jnp.eye(6),  # W
        1 * jnp.eye((n_delay - 1)),  # q
        1 * jnp.eye(3 * 6),  # Wq
    )

    B_logI = jnp.eye(n_delay)[:, :1]
    B_logrho = jnp.zeros((n_delay, 1))
    B_logM = jnp.eye(n_delay)[:, :1]
    B_logW = jnp.hstack(
        [
            jnp.eye(n_delay)[:, :1],  # W_t
            jnp.zeros((n_delay, 5)),  # W_t-s
        ]
    )
    B_q = jnp.eye(n_delay)[:, 1:]
    B_Wq = jnp.hstack(
        [
            jnp.eye(n_delay)[:, 1:2],
            jnp.zeros((n_delay, 5)),  # W_t-s
            jnp.eye(n_delay)[:, 2:3],
            jnp.zeros((n_delay, 5)),  # W_t-s
            jnp.eye(n_delay)[:, 3:],
            jnp.zeros((n_delay, 5)),  # W_t-s
        ]
    )
    B = jnp.hstack(
        [
            B_logI,
            B_logrho,
            B_logM,
            B_logW,
            B_q,
            B_Wq,
            # jnp.zeros((n_delay, 6 * (n_delay - 1))),  # q_t-s
        ]
    )

    A = jnp.broadcast_to(A, (n, m, m))
    D = jnp.broadcast_to(D, (n, m, l))
    Sigma = jnp.broadcast_to(Sigma, (n, l, l))
    B = jnp.broadcast_to(B, (np1, p, m))

    def poisson_obs(s, xi):
        log_I_W, q = jnp.split(s, [1], axis=-1)
        log_p = to_log_probs(q)
        log_rate = log_I_W + log_p
        return Poisson(log_rate=log_rate)

    def negbinom_obs(s, xi):
        log_I_W, q = jnp.split(s, [1], axis=-1)
        log_p = to_log_probs(q)
        log_mu = log_I_W + log_p
        return NBinom(r, logits=log_mu - jnp.log(r))

    dist = poisson_obs  # negbinom_obs
    xi = jnp.empty((np1, p, 1))

    return PGSSM(u, A, D, Sigma0, Sigma, v, B, dist, xi)

# %% ../../nbs/4 Models/4.1 Removing reporting delays and weekday effects/10_model.ipynb 10
def account_for_nans(model: PGSSM, y, missing_indices) -> tuple[PGSSM, Float]:
    # only works for Poisson!
    # missing_indices = jnp.isnan(y)

    y_missing = jnp.nan_to_num(y, nan=0.0)

    v = model.v.at[missing_indices].set(0.0)
    B = model.B.at[missing_indices].set(0.0)

    xi_missing = jnp.ones_like(y).at[missing_indices].set(0.0)[..., None]
    xi = jnp.concatenate([xi_missing, model.xi], -1)

    def missing_dist(s, xi):
        xi_missing, old_xi = xi[..., 0], xi[..., 1:]
        old_dist = model.dist(s, old_xi)
        # if xi == 0. the log rate becomes -inf, so dist is dirac_0
        return Poisson(log_rate=old_dist.log_rate + jnp.log(xi_missing))

    model_missing = PGSSM(
        u=model.u,
        A=model.A,
        D=model.D,
        Sigma0=model.Sigma0,
        Sigma=model.Sigma,
        v=v,
        B=B,
        dist=missing_dist,
        xi=xi,
    )

    return model_missing, y_missing

# %% ../../nbs/4 Models/4.1 Removing reporting delays and weekday effects/10_model.ipynb 16
# LA monkey patch
from isssm.kalman import kalman, smoothed_signals
from isssm.typing import GLSSM, GLSSMProposal, ConvergenceInformation
from isssm.laplace_approximation import default_link, vvmap, vdiag
from jax.scipy.optimize import minimize
from functools import partial
from isssm.util import converged
from jax import jacfwd, hessian, jacrev
from jax.lax import while_loop
import isssm.laplace_approximation


def _initial_guess(xi_t, y_t, dist, link=default_link):
    return jnp.array([jnp.log(y_t.sum() + 1), *jnp.zeros(3)])


isssm.laplace_approximation._initial_guess = _initial_guess
from ..patch import full_deps
